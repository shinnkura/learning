{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTHqkI6yKpAx"
   },
   "source": [
    "# モデルの実装のまとめと学習の導入\n",
    "本単元は、総まとめに当たる単元になるので重要事項を再度確認しよう。\n",
    "\n",
    "> 本講座のタスク\n",
    "* タスクの内容：画像に写っている１文字の数字を何か判定する\n",
    "    * 用意したデータ：60,000枚の手書き数字が写ったラベル付きの画像データ(MNISTデータセット)  \n",
    "    * 目的：精度を重視する  \n",
    "\n",
    "> 機械学習の流れ\n",
    "1. ~アルゴリズムの選択~：ディープラーニングを選択\n",
    "2. ~前処理~：MNISTデータセットには必要なし\n",
    "3. モデルの学習\n",
    "4. 評価・検証\n",
    "\n",
    "この単元では**MLPモデルを学習させる方法**をメインに「3.モデルの学習」,「4.評価・検証」の実装をしていくぞ！  \n",
    "具体的には、モデルの学習に使う`train()`関数と、評価・検証に使う`test()`関数の実装だ。  \n",
    "\n",
    "## この単元の目標\n",
    "- MLPモデルを学習できるようになろう\n",
    "- MLPモデルをテストできるようになろう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wK8vNgAaVv3_"
   },
   "source": [
    "## 0. 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZJTRwduamDI"
   },
   "outputs": [],
   "source": [
    "# 本章で使うモジュールのインポート\n",
    "from torch import utils\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqQh5xZsPPPY"
   },
   "source": [
    "### 【MNISTデータセット】\n",
    "まずは、学習に使うデータセットを準備しよう。(MNISTについて忘れた人は単元1を確認しよう)  \n",
    "\n",
    "pytorchには、データセットがライブラリとしていくつか用意（実際にはダウンロードする関数）されており、MNISTもその1つだ。  \n",
    "\n",
    "以下のコードを実行すれば、\n",
    "* データセットの用意(ダウンロード)\n",
    "* 過学習回避のため、用意したデータセットを学習用と検証用に分ける  \n",
    "    * 下記のプログラムでは最初から別れたデータをダウンロードしている\n",
    "* ミニバッチごとにデータを纏める  \n",
    "    * バッチサイズは100、ランダムにバッチデータを決めることで効果的な学習になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4-uAOWgPjbh"
   },
   "outputs": [],
   "source": [
    "## こうやってダウンロードして使うことができるよ\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())  # 学習用データセット\n",
    "train_loader = utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)  # ミニバッチごとにデータを纏める(学習時にはshuffle=True)\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())  # 検証用データセット\n",
    "test_loader = utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)  # ミニバッチごとにデータを纏める(学習時にはshuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XowdNPCCYfGF"
   },
   "source": [
    "### 【モデルの定義】\n",
    "次に、学習を行うためのモデルを準備しよう。  \n",
    "行うタスクは、**「28*28画素の白黒画像を10クラス分類する」**事なので、  \n",
    "入力ノードの数は784（=28*28）個で、出力ノードの数は10個で良いだろう。\n",
    "\n",
    "よって、以下の条件のMLPモデルをクラスとして定義する。  \n",
    "- 「入力層、中間層、出力層」のノードの数が「784（=28×28）、512、10」\n",
    "- 中間層の出力に活性化関数`relu()`を適用\n",
    "- 損失関数は`MSELoss()`\n",
    "- 最適化関数は`Adam()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRPWplc-ZGYF"
   },
   "outputs": [],
   "source": [
    "class mlp_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.parameters())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DYWI7-a2V7yq"
   },
   "source": [
    "## 1. train()関数の実装\n",
    "それでは、**`train()`関数の実装**を行っていこう。\n",
    "実装にあたり、気をつける点が2点あるので\n",
    "- 2次元の画像であるテンソルを1次元のテンソルに変換する。\n",
    "- 損失を求めるために正解データをone-hotベクトル化する。\n",
    "\n",
    "MLPはその構造上、**2次元以上である画像データをその形状のまま入力として受け取る事ができない。**  \n",
    "よって、画像を行や列で区切るなどして**1次元のテンソルに変換してからモデルに入力**する。  \n",
    "今回は、形状変形のために`reshape()`を使おう。\n",
    "\n",
    "また、モデルの出力は**各クラスの予測確率に相関したベクトル**であるのに対し、**正解ラベルはクラス名（0~9の値）**であるため、  \n",
    "そのままではMSEを計算する事ができない。  \n",
    "そこで、正解ラベルを「one-hotベクトルに変換」することで、モデルの予測結果との損失計算を可能にする。  \n",
    "【one-hotベクトル化の例】\n",
    "- 正解ラベル「1」 → `[0,1,0,0,0,0,0,0,0,0]` （=「1」である確率が1の確率ベクトル）\n",
    "- 正解ラベル「7」 → `[0,0,0,0,0,0,0,1,0,0]` （=「7」である確率が1の確率ベクトル）\n",
    "\n",
    "以上のことを踏まえて、例題を見ながら`train()`関数の実装方法を確認しよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CB7fXVCnwRnd"
   },
   "source": [
    "【例題】 `train()`関数を実装する。 \n",
    "`train()`関数では、引数に`model`（学習するモデル）と`train_loader`（学習データローダ）を受け取り、  \n",
    "`train_loader`を「ミニバッチ=ある程度の数のデータのまとまり」ごとにループさせて学習を行う。  \n",
    "この1ループは、次の流れで進む。\n",
    "1. バッチごとのデータをモデルへ順伝播させる\n",
    "2. 正解ラベルと比較して損失を計算する\n",
    "3. 損失から最適化を行う\n",
    "4. 次のバッチへ\n",
    "\n",
    "これに加えて**「画像データの1次元化」**と**「正解ラベルのone-hotベクトル化」**を忘れないようにしよう。  \n",
    "`torch.eye(クラス数)[バッチごとのデータ]`と記述すると、`バッチごとのデータ`の1要素に対してone-hotベクトル化することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22EuWFr4WQGR"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    # 今は学習時であることを明示するコード\n",
    "    model.train()\n",
    "    # ミニバッチごとにループさせる,train_loaderの中身を出し切ったら1エポックとなる\n",
    "    for batch_imgs, batch_labels in train_loader:\n",
    "        batch_imgs = batch_imgs.reshape(-1, 28*28*1)  # 画像データを1次元に変換\n",
    "        labels = torch.eye(10)[batch_labels]  # 正解ラベルをone-hotベクトルへ変換\n",
    "\n",
    "        outputs = model(batch_imgs)  # 順伝播\n",
    "        model.optimizer.zero_grad()  # 勾配を初期化（前回のループ時の勾配を削除）\n",
    "        loss = model.criterion(outputs, labels)  # 損失を計算\n",
    "        loss.backward()  # 逆伝播で勾配を計算\n",
    "        model.optimizer.step()  # 最適化\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTrJa_Bn_eOn"
   },
   "source": [
    "以上のコードが、モデルの学習を行うプログラムの核にあたる。  \n",
    "\n",
    "しかし、このままでは学習進捗の確認ができないので、「正答率」と「損失」を出力できるように、以下のように追記する。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8euG-MK98LR"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    # 今は学習時であることを明示するコード\n",
    "    model.train()\n",
    "\n",
    "    ### 追記部分1 ###\n",
    "    # 正しい予測数、損失の合計、全体のデータ数を数えるカウンターの0初期化\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    total_data_len = 0\n",
    "    ### ###\n",
    "\n",
    "    # ミニバッチごとにループさせる,train_loaderの中身を出し切ったら1エポックとなる\n",
    "    for batch_imgs, batch_labels in train_loader:\n",
    "        batch_imgs = batch_imgs.reshape(-1, 28*28*1)  # 画像データを1次元に変換\n",
    "        labels = torch.eye(10)[batch_labels]  # 正解ラベルをone-hotベクトルへ変換\n",
    "\n",
    "        outputs = model(batch_imgs)  # 順伝播\n",
    "        model.optimizer.zero_grad()  # 勾配を初期化（前回のループ時の勾配を削除）\n",
    "        loss = model.criterion(outputs, labels)  # 損失を計算\n",
    "        loss.backward()  # 逆伝播で勾配を計算\n",
    "        model.optimizer.step()  # 最適化\n",
    "       \n",
    "        ### 追記部分2 ###\n",
    "        # ミニバッチごとの正答率と損失を求める\n",
    "        _, pred_labels = torch.max(outputs, axis=1)  # outputsから必要な情報(予測したラベル)のみを取り出す。\n",
    "        batch_size = len(batch_labels)  # バッチサイズの確認\n",
    "        for i in range(batch_size):  # データ一つずつループ,ミニバッチの中身出しきるまで\n",
    "            total_data_len += 1  # 全データ数を集計\n",
    "            if pred_labels[i] == batch_labels[i]:\n",
    "                total_correct += 1 # 正解のデータ数を集計\n",
    "        total_loss += loss.item()  # 全損失の合計\n",
    "\n",
    "    # 今回のエポックの正答率と損失を求める\n",
    "    accuracy = total_correct/total_data_len*100  # 予測精度の算出\n",
    "    loss = total_loss/total_data_len  # 損失の平均の算出\n",
    "    return accuracy, loss\n",
    "    ### ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10221,
     "status": "ok",
     "timestamp": 1593136130415,
     "user": {
      "displayName": "Kurusu Yuugo",
      "photoUrl": "",
      "userId": "00117977046560544733"
     },
     "user_tz": -540
    },
    "id": "wDSSBkxZZPu0",
    "outputId": "7f529153-9c33-4a2d-ecc4-ba4349d65cdd"
   },
   "outputs": [],
   "source": [
    "# モデルを宣言する\n",
    "model = mlp_net()\n",
    "\n",
    "# 学習させ、その結果を表示する\n",
    "acc, loss = train(model, train_loader)\n",
    "print(f'正答率: {acc}, 損失: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCP1JwtARCI_"
   },
   "source": [
    "- ```\n",
    "正答率： {95.0前後}, 損失: {0.0002前後}\n",
    "```\n",
    "と表示されていれば成功だ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRTxU6U9QPgR"
   },
   "source": [
    "【問題】 新しいMLPモデル`mlp_net_2()`をクラスとして定義して、学習、結果を例題と同様に表示しよう。  \n",
    "ただし、以下の条件にあるようにハイパーパラメータを指定すること。\n",
    "- 宣言する`mlp_net_2()`のインスタンス名（変数名）は`model_2`とすること\n",
    "- 中間層のノードの数を`256`にする\n",
    "- `optim.Adam()`の引数`lr`に`0.01`を指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfXBJ_IGRTpv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfXBJ_IGRTpv"
   },
   "outputs": [],
   "source": [
    "# モデルを宣言する\n",
    "model_2 = mlp_net_2()\n",
    "\n",
    "# 学習させ、その結果を表示する\n",
    "acc, loss = train(model_2, train_loader)\n",
    "print(f'正答率: {acc}, 損失: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PqywSvzSEvM"
   },
   "source": [
    "- ```\n",
    "正答率： {90.0前後}, 損失: {0.00025前後}\n",
    "```\n",
    "と表示されていれば成功だ。\n",
    "- 恐らく、例題よりも正答率は下がり、損失は大きくなったのではないだろうか。  \n",
    "このように、ハイパーパラメータは学習に大きく影響するということを覚えておこう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foTqDLiCk2g5"
   },
   "source": [
    "## test()関数の実装\n",
    "次は、テストデータを使った評価を行う`test()`関数を実装する。  \n",
    "とは言っても、`train()`関数から「損失計算」や「最適化」の要素を取り除けば良いだけだ。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FP4c6sieZfOj"
   },
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    # モデルを評価モードにする\n",
    "    model.eval()\n",
    "    # 正しい予測数、全体のデータ数を数えるカウンターの0初期化\n",
    "    total_data_len = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch_imgs, batch_labels in data_loader:\n",
    "        outputs = model(batch_imgs.reshape(-1, 28*28*1))  # 順伝播（=予測）\n",
    "         \n",
    "        # ミニバッチごとの集計\n",
    "        _, pred_labels = torch.max(outputs, axis=1)  # outputsから必要な情報(予測したラベル)のみを取り出す。\n",
    "        batch_size = len(pred_labels)  # バッチサイズの確認\n",
    "        for i in range(batch_size):  # データ一つずつループ,ミニバッチの中身出しきるまで\n",
    "            total_data_len += 1  # 全データ数を集計\n",
    "            if pred_labels[i] == batch_labels[i]:\n",
    "                total_correct += 1 # 正解のデータ数を集計\n",
    "\n",
    "    # 1エポック分の集計\n",
    "    acc = 100.0 * total_correct/total_data_len  # 予測精度の算出\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHTpEKJBNK3p"
   },
   "source": [
    "【例題】 学習させた`mlp_net`と`test_loader`を使って、テストを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18965,
     "status": "ok",
     "timestamp": 1593136139179,
     "user": {
      "displayName": "Kurusu Yuugo",
      "photoUrl": "",
      "userId": "00117977046560544733"
     },
     "user_tz": -540
    },
    "id": "DDAwyPSSkQH-",
    "outputId": "3b9e2c1c-e2ea-4cd4-8b7e-f79514184bd1"
   },
   "outputs": [],
   "source": [
    "test_acc = test(model, test_loader)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DH5RIZMhNefA"
   },
   "source": [
    "- 正答率はおよそ`95%`前後になるだろう。それであれば成功だ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WIMlmcOzShRs"
   },
   "source": [
    "【問題】 学習させた`mlp_net_2`と`test_loader`を使って、テストを行ってみよう。テストデータの正答率を出力すれば良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20024,
     "status": "ok",
     "timestamp": 1593136140243,
     "user": {
      "displayName": "Kurusu Yuugo",
      "photoUrl": "",
      "userId": "00117977046560544733"
     },
     "user_tz": -540
    },
    "id": "RkUTYIgpShRt",
    "outputId": "5db893a4-996b-410c-c27f-f273fc249293"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trzhGmgsShRx"
   },
   "source": [
    "- 恐らく正答率は例題と同等かそれ以下になるだろう。それであれば成功だ。\n",
    "- ハイパーパラメータの影響によって、学習データ・テストデータともに予測精度が落ちている可能性が高い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1utcb96gbbe"
   },
   "source": [
    "## まとめ\n",
    "MLPモデルを実装し、テストした！\n",
    "\n",
    "Pytorchを使ってのプログラミングは理論より、簡単だったのではないだろうか？\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wq8H0sGT_Vci"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7_モデルの学習.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
