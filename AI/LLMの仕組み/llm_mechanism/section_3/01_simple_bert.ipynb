{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXkHKM4vR48SO99XRRabUK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/llm_mechanism/blob/main/section_3/01_simple_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv454lBK1YCc"
      },
      "source": [
        "# シンプルなBERTの実装\n",
        "訓練済みのBERTのモデルを使用し、文章の一部の予測、及び2つの文章が連続しているかどうかの判定を行います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Ozfz3NhltP"
      },
      "source": [
        "## ライブラリのインストール\n",
        "ライブラリTransformersをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_mDYVlb-sqi"
      },
      "source": [
        "!pip install transformers==4.26.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb5gVyYF2vjL"
      },
      "source": [
        "## 文章の一部の予測\n",
        "文章における一部の単語をMASKし、それをBERTのモデルを使って予測します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6oFZnS21Mqs"
      },
      "source": [
        "import torch\n",
        "from transformers import BertForMaskedLM\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "text = \"[CLS] I played baseball with my friends at school yesterday [SEP]\"\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "words = tokenizer.tokenize(text)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3Y32Tl55dSl"
      },
      "source": [
        "文章の一部をMASKします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_H50V7b5RM0"
      },
      "source": [
        "msk_idx = 3\n",
        "words[msk_idx] = \"[MASK]\"  # 単語を[MASK]に置き換える\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBXgAn9s528_"
      },
      "source": [
        "単語を対応するインデックスに変換します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm4qbMPW56-w"
      },
      "source": [
        "word_ids = tokenizer.convert_tokens_to_ids(words)  # 単語をインデックスに変換\n",
        "word_tensor = torch.tensor([word_ids])  # テンソルに変換\n",
        "print(word_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y76O88877cB_"
      },
      "source": [
        "BERTのモデルを使って予測を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2NWREc77gQC"
      },
      "source": [
        "msk_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "msk_model.eval()\n",
        "\n",
        "x = word_tensor\n",
        "y = msk_model(x)  # 予測\n",
        "result = y[0]\n",
        "print(result.size())  # 結果の形状\n",
        "\n",
        "_, max_ids = torch.topk(result[0][msk_idx], k=5)  # 最も大きい5つの値\n",
        "result_words = tokenizer.convert_ids_to_tokens(max_ids.tolist())  # インデックスを単語に変換\n",
        "print(result_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Su6QTCAAgFS"
      },
      "source": [
        "## 文章が連続しているかどうかの判定\n",
        "BERTのモデルを使って、2つの文章が連続しているかどうかの判定を行います。  \n",
        "以下の関数`show_continuity`では、2つの文章の連続性を判定し、表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC0nihWMAtgG"
      },
      "source": [
        "from transformers import BertForNextSentencePrediction\n",
        "\n",
        "nsp_model = BertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\")\n",
        "nsp_model.eval()  # 評価モード\n",
        "\n",
        "def show_continuity(text1, text2):\n",
        "    # トークナイズ\n",
        "    tokenized = tokenizer(text1, text2, return_tensors=\"pt\")\n",
        "    print(\"Tokenized:\", tokenized)\n",
        "\n",
        "    # 予測と結果の表示\n",
        "    y = nsp_model(**tokenized)  # 予測\n",
        "    print(\"Result:\", y)\n",
        "    pred = torch.softmax(y.logits, dim=1)  # Softmax関数で確率に変換\n",
        "    print(str(pred[0][0].item()*100) + \"%の確率で連続しています。\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWogb8nFIQMg"
      },
      "source": [
        "`show_continuity`関数に、自然につながる2つの文章を与えます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaUmof1yF_rD"
      },
      "source": [
        "text1 = \"What is baseball ?\"\n",
        "text2 = \"It is a game of hitting the ball with the bat.\"\n",
        "show_continuity(text1, text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKjotaOCIeeK"
      },
      "source": [
        "`show_continuity`関数に、自然につながらない2つの文章を与えます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4qAKBlcGRYb"
      },
      "source": [
        "text1 = \"What is baseball ?\"\n",
        "text2 = \"This food is made with flour and milk.\"\n",
        "show_continuity(text1, text2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}