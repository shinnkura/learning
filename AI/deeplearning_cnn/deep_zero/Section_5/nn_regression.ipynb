{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの構築（回帰）\n",
    "ここからはニューラルネットワーク、すなわち複数のニューロンからなるネットワークを実装します。  \n",
    "まず、出力が連続的な数値になる問題、すなわち回帰問題を扱います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●実装するニューラルネットワーク\n",
    "今回は、以下に示す3層のシンプルなニューラルネットワークを実装します。  \n",
    "\n",
    "<img src=\"images/nn_regression.png\">\n",
    "\n",
    "このニューラルネットワークは、入力層（ニューロン数: n=2）、中間層（n=2）、出力層（n=1）の3層構造です。  \n",
    "中間層の活性化関数はシグモイド関数で、出力層の活性化関数は回帰であるため恒等関数になります。  \n",
    "\n",
    "ディープラーニングでは近年中間層の活性化関数にReLUを使うことが多いのですが、今回は結果を連続的に表示するためにシグモイド関数を使います。  \n",
    "このニューラルネットワークに入力を順伝播させて、出力を今回もグリッドで表示します。  \n",
    "そして、出力の傾向を観察します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●各層の実装\n",
    "3層のニューラルネットワークの各層を実装します。  \n",
    "入力層は入力をそのまま受け取るのみなので、解説は省略します。  \n",
    "中間層は、次のように関数で実装します。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 中間層\n",
    "def middle_layer(x, w, b):\n",
    "    u = np.dot(x, w) + b\n",
    "    return 1/(1+np.exp(-u)) # シグモイド関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この関数は、引数として中間層への入力（`x`）、重み（`w`）とバイアス（`b`）を受け取ります。  \n",
    "そして、以下の箇所でNumpyのdot関数を用いて行列wとベクトル`x`の行列積を計算し、バイアスを足し合わせます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = np.dot(x, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行列積を用いる理由は以前に解説しています。  \n",
    "このコードは、ニューロンのネットワーク化の際に解説した以下の式に対応します。\n",
    "\n",
    "$$  \\begin{aligned} \\\\\n",
    "\\vec{u_j} & = \\vec{x_i}W + \\vec{b_j} \\\\\n",
    "  \\end{aligned}\n",
    "$$ \n",
    "\n",
    "得られた`u`を活性化関数であるシグモイド関数に入れて、中間層の出力を得ることができます。  \n",
    "\n",
    "出力層も、中間層と同様に関数で実装します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 出力層\n",
    "def output_layer(x, w, b):\n",
    "    u = np.dot(x, w) + b\n",
    "    return u  # 恒等関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引数、及び`u`の計算は中間層と同様です。  \n",
    "中間層との違いは、活性化関数が恒等関数である点です。\n",
    "\n",
    "重みは、次のようにNumpyの配列を用いた行列として実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 重み\n",
    "w_im = np.array([[4.0,4.0],\n",
    "                 [4.0,4.0]])  # 中間層 2x2の行列\n",
    "w_mo = np.array([[1.0],\n",
    "                 [-1.0]])     # 出力層 2x1の行列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力層のニューロン数は2、中間層のニューロン数は2なので、中間層には2x2=4個の重みが必要になります。  \n",
    "また、中間層のニューロン数は2、出力層のニューロン数は1なので、出力層には2x1=2個の重みが必要になります。  \n",
    "\n",
    "バイアスは次のようにベクトルとして実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# バイアス\n",
    "b_im = np.array([3.0,-3.0]) # 中間層\n",
    "b_mo = np.array([0.1])      # 出力層 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バイアスの数はニューロンの数に等しいので、中間層には2個、出力層には1個のバイアスが必要になります。  \n",
    "なお、重みとバイアスの値は適当な値を設定しています。\n",
    "\n",
    "以上を踏まえて、順伝播を次のように実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 順伝播\n",
    "inp = np.array([...])               # 入力層\n",
    "mid = middle_layer(inp, w_im, b_im) # 中間層\n",
    "out = output_layer(mid, w_mo, b_mo) # 出力層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力を重みとバイアスとともに中間層の関数に渡します。  \n",
    "そして、中間層の出力を重みとバイアスとともに出力層の関数に渡して、出力層の出力を得ます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●全体のコード\n",
    "ニューラルネットワークのコード全体は、以下の通りです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# x、y座標\n",
    "X = np.arange(-1.0, 1.0, 0.2)  # 要素数は10個\n",
    "Y = np.arange(-1.0, 1.0, 0.2)\n",
    "\n",
    "# 出力を格納する10x10のグリッド\n",
    "Z = np.zeros((10,10))\n",
    "\n",
    "# 重み\n",
    "w_im = np.array([[4.0,4.0],\n",
    "                 [4.0,4.0]])  # 中間層 2x2の行列\n",
    "w_mo = np.array([[1.0],\n",
    "                 [-1.0]])     # 出力層 2x1の行列\n",
    "\n",
    "# バイアス\n",
    "b_im = np.array([3.0,-3.0]) # 中間層\n",
    "b_mo = np.array([0.1])      # 出力層 \n",
    "\n",
    "# 中間層\n",
    "def middle_layer(x, w, b):\n",
    "    u = np.dot(x, w) + b\n",
    "    return 1/(1+np.exp(-u)) # シグモイド関数\n",
    "\n",
    "# 出力層\n",
    "def output_layer(x, w, b):\n",
    "    u = np.dot(x, w) + b\n",
    "    return u  # 恒等関数\n",
    "\n",
    "# グリッドの各マスでニューラルネットワークの演算\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        \n",
    "        # 順伝播\n",
    "        inp = np.array([X[i], Y[j]])        # 入力層\n",
    "        mid = middle_layer(inp, w_im, b_im) # 中間層\n",
    "        out = output_layer(mid, w_mo, b_mo) # 出力層\n",
    "        \n",
    "        # グリッドにNNの出力を格納\n",
    "        Z[j][i] = out[0]\n",
    "\n",
    "# グリッドの表示\n",
    "plt.imshow(Z, \"gray\", vmin = 0.0, vmax = 1.0)\n",
    "plt.colorbar()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グリッドの形式は単一ニューロンの際と同じです。  \n",
    "単一ニューロンの際は白の領域と黒の領域の2つに分けるのみであったのに対して、このニューラルネットワークを用いると白が黒に挟まれる結果となりました。  \n",
    "より複雑な条件で、ニューロンが興奮するようになっています。 \n",
    "\n",
    "なお、グリッドに出力を格納する際に、`out`に`[0]`が付いているのは`out`が要素数1の配列だからです。  \n",
    "\n",
    "重みとバイアスを様々な値に変更し、ニューラルネットワークの表現力を試してみましょう。  \n",
    "重みとバイアスが変わると、グリッドにおける出力の分布が様々な形状に変化します。  \n",
    "\n",
    "複数のニューロンをネットワーク化しニューラルネットワークを構築することで、単一ニューロンと比べて表現力が向上することが確認されました。   \n",
    "ニューロンの数や層の数をさらに増すことで、より複雑な分布を出力することも可能です。  \n",
    "複雑な出力分布を利用することで、ニューラルネットワークは高度な予測や分類ができるようになります。  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
