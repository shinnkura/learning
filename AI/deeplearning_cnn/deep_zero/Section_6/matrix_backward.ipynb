{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 行列による逆伝播の演算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●重みの勾配を求める\n",
    "逆伝播においては、以前に出力層の勾配や中間層の勾配を求めた際と同様に、まず$\\delta$（デルタ）を求めます。  \n",
    "$\\delta$の求め方は層の種類や活性化関数の種類により異なりますが、これを行列$\\Delta$で表すと以下のようになります。\n",
    "\n",
    "$$  \\begin{aligned} \\\\\n",
    "\\Delta & = \\left(\n",
    "    \\begin{array}{cccc}\n",
    "      \\delta_{11} & \\delta_{12} & \\ldots & \\delta_{1n} \\\\\n",
    "      \\delta_{21} & \\delta_{22} & \\ldots & \\delta_{2n} \\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "      \\delta_{h1} & \\delta_{h2} & \\ldots & \\delta_{hn} \\\\\n",
    "    \\end{array}\n",
    "  \\right)\n",
    "  \\end{aligned}\n",
    " $$ \n",
    "\n",
    "$\\Delta$は、層の出力$Y$と同じく、h x n、すなわち(バッチサイズ)x(ニューロン数)の行列になります。  \n",
    "\n",
    "この$\\delta$をもとに、各勾配を求めます。  \n",
    "$\\delta$の求め方以外は、出力層、中間層ともに各勾配の求め方は共通です。  \n",
    "重みの勾配$\\partial w_{ij}$を求めるためは、以前に導出した以下の式を用います。  \n",
    "\n",
    "$$\\partial w_{ij} = \\frac{\\partial E}{\\partial w_{ij}} = y_i\\delta_{j} $$\n",
    "\n",
    "上の層の出力$y_i$は、この層のへの入力に等しいので、$y$は$x$に置き換えます。  \n",
    "バッチに対応するためには、求めた勾配をバッチ内で足し合わせます。  \n",
    "これは、以前に「エポックとバッチ」で解説した式をもとに、以下のように表すことができます。  \n",
    "\n",
    "$$ \\sum_{k=1}^{h} \\frac{\\partial E_k}{\\partial w_{ij}}  $$\n",
    "\n",
    "以上を踏まえて、バッチ対応した重みの勾配の行列$\\partial W$は、次のようにして求めることができます。  \n",
    "\n",
    "$$  \\begin{aligned} \\\\\n",
    "\\partial W & = X^{\\mathrm{T}}\\Delta \\\\\n",
    "& = \\left(\n",
    "    \\begin{array}{cc}\n",
    "      x_{11} & x_{21} & \\ldots & x_{h1} \\\\\n",
    "      x_{12} & x_{22} & \\ldots & x_{h2} \\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "      x_{1m} & x_{2m} & \\ldots & x_{hm} \\\\\n",
    "    \\end{array}\n",
    "  \\right)\n",
    "\\left(\n",
    "    \\begin{array}{cccc}\n",
    "      \\delta_{11} & \\delta_{12} & \\ldots & \\delta_{1n} \\\\\n",
    "      \\delta_{21} & \\delta_{22} & \\ldots & \\delta_{2n} \\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "      \\delta_{h1} & \\delta_{h2} & \\ldots & \\delta_{hn} \\\\\n",
    "    \\end{array}\n",
    "  \\right) \\\\\n",
    "& = \\left(\n",
    "    \\begin{array}{cc}\n",
    "      \\sum\\limits_{k=1}^hx_{k1}\\delta_{k1} & \\sum\\limits_{k=1}^hx_{k1}\\delta_{k2} & \\ldots & \\sum\\limits_{k=1}^hx_{k1}\\delta_{kn} \\\\\n",
    "      \\sum\\limits_{k=1}^hx_{k2}\\delta_{k1} & \\sum\\limits_{k=1}^hx_{k2}\\delta_{k2} & \\ldots & \\sum\\limits_{k=1}^hx_{k2}\\delta_{kn} \\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "      \\sum\\limits_{k=1}^hx_{km}\\delta_{k1} & \\sum\\limits_{k=1}^hx_{km}\\delta_{k2} & \\ldots & \\sum\\limits_{k=1}^hx_{km}\\delta_{kn} \\\\\n",
    "    \\end{array}\n",
    "  \\right)\n",
    "  \\end{aligned}\n",
    "  $$ \n",
    "\n",
    "$X$と$\\Delta$の行列積をとるためには、$X^{\\mathrm{T}}$のように$X$を転置をして前の行列の列数と後ろの行列の行数を合わせる必要があります。  \n",
    "結果的に得られた行列の各要素は、バッチ内で総和をとったものになっています。  \n",
    "また、この行列のサイズはm x nであり、$W$のサイズと一致しています。 \n",
    "\n",
    "以上は、次のようなシンプルコードで記述することができます。    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_w = np.dot(x.T, delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grad_w`は重みの勾配の行列$\\partial W$で、`x`は入力の行列$X$、`delta`は$\\delta$の行列$\\Delta$を表します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●バイアスの勾配を求める\n",
    "バイアスの勾配は、以前に導出したバイアスの勾配の式を使って求めることができます。  \n",
    "\n",
    "$$ \\partial b_j = \\delta_{j}$$ \n",
    "\n",
    "バッチ対応したバイアスの勾配は、次のように$\\delta$をバッチ内で足し合わせることで求めることができます。\n",
    "\n",
    "$$ \\sum_{k=1}^{h} \\frac{\\partial E_k}{\\partial b_j}  $$\n",
    "\n",
    "これは、Numpyを用いて次のように実装することができます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_b = np.sum(delta, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grad_b`はバイアスの勾配を表すベクトルです。  \n",
    "Numpyのsum関数でaxisに0を指定すると、行列の縦方向で要素が足し合わされたベクトルを得ることができます。  \n",
    "これにより、バッチ内で$\\delta$を足し合わせることができます。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●入力の勾配を求める\n",
    "上の層の出力の勾配（この層の入力の勾配）を求めます。  \n",
    "これは、上の層の$\\delta$を求めるのに用いられます。  \n",
    "以前に導出した式は次の通りです。  \n",
    "\n",
    "（式 1）\n",
    "$$ \\partial y_j = \\sum_{r=1}^n \\delta_r w_{jr} $$\n",
    "\n",
    "重みの勾配と同様に、上の層の出力$y_j$はこの層のへの入力に等しいので、$y$を$x$に置き換えます。  \n",
    "そして、$\\partial y$をバッチ対応した行列にしたものを、$\\partial X$とします。   \n",
    "これは次ように求めることができます。\n",
    "\n",
    "$$  \\begin{aligned} \\\\\n",
    "\\partial X & = \\Delta W^{\\mathrm{T}} \\\\\n",
    "& = \\left(\n",
    "    \\begin{array}{cccc}\n",
    "      \\delta_{11} & \\delta_{12} & \\ldots & \\delta_{1n} \\\\\n",
    "      \\delta_{21} & \\delta_{22} & \\ldots & \\delta_{2n} \\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "      \\delta_{h1} & \\delta_{h2} & \\ldots & \\delta_{hn} \\\\\n",
    "    \\end{array}\n",
    "  \\right) \n",
    "\\left(\n",
    "    \\begin{array}{cccc}\n",
    "      w_{11} & w_{21} & \\ldots & w_{m1} \\\\\n",
    "      w_{12} & w_{22} & \\ldots & w_{m2} \\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "      w_{1n} & w_{2n} & \\ldots & w_{mn} \\\\\n",
    "    \\end{array}\n",
    "  \\right)\\\\\n",
    "& = \\left(\n",
    "    \\begin{array}{cc}\n",
    "      \\sum\\limits_{k=1}^n\\delta_{1k}w_{1k} & \\sum\\limits_{k=1}^n\\delta_{1k}w_{2k} & \\ldots & \\sum\\limits_{k=1}^n\\delta_{1k}w_{mk} \\\\\n",
    "      \\sum\\limits_{k=1}^n\\delta_{2k}w_{1k} & \\sum\\limits_{k=1}^n\\delta_{2k}w_{2k} & \\ldots & \\sum\\limits_{k=1}^n\\delta_{2k}w_{mk} \\\\\n",
    "      \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "      \\sum\\limits_{k=1}^n\\delta_{hk}w_{1k} & \\sum\\limits_{k=1}^n\\delta_{hk}w_{2k} & \\ldots & \\sum\\limits_{k=1}^n\\delta_{hk}w_{mk}\\\\\n",
    "    \\end{array}\n",
    "  \\right)\n",
    "  \\end{aligned}\n",
    "  $$ \n",
    "\n",
    "$\\Delta$と$W$の行列積をとるために、$W^{\\mathrm{T}}$のように$W$を転置します。  \n",
    "これにより$\\Delta$の列数と$W$の行数が一致し、行列積が計算できます。  \n",
    "結果的に得られた行列の各要素は、この層のニューロンで総和をとったものになっており、（式 1）を表していることが分かります。\n",
    "\n",
    "上記は、次のコードで記述することができます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_x = np.dot(delta, w.T) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grad_x`は入力の勾配の行列$\\partial X$です。  \n",
    "\n",
    "以上により、逆伝播を行列の演算で表現することができました。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
