{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習の準備\n",
    "ディープラーニングによりIrisを分類するための準備です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●訓練データとテストデータ\n",
    "今回はIrisデータセットを訓練データとテストデータに分割します。  \n",
    "訓練データでニューラルネットワークを訓練し、テストデータでその汎化性能を評価します。  \n",
    "\n",
    "データセット全体を、どの割合で訓練データとテストデータに分けるのかは、判断に慎重を要する問題です。  \n",
    "テストデータの割合を増やせば検証の信頼性が高くなりますが、訓練データの割合を小さくしすぎると、学習に必要な訓練データのサンプル数が少なくなってしまいます。  \n",
    "一般的に、テストデータの割合を20%から30%にするのが妥当な線なのですが、今回は訓練データによる結果とテストデータによる結果をなるべく同等の条件で比較したいので、Irisデータセットのうち半分をテストデータとし、残りを訓練データにします。  \n",
    "\n",
    "学習中は、訓練データの誤差とテストデータの誤差の変化を記録します。  \n",
    "また、学習後のニューラルネットワークが正しく品種分類を行えるかどうかの指標として、訓練データとテストデータそれぞれで正解率を測定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●ネットワーク構成\n",
    "今回は以下の図で示すニューラルネットワークを構築します。\n",
    "\n",
    "<img src=\"images/network.png\">\n",
    "\n",
    "入力層、出力層の間に中間層が2つあり、4層のニューラルネットワークになります。花ごとに4つの測定値があるので、入力層には4つのニューロンを置きます。  \n",
    "また、今回は入力を3種類の品種に分類するので、出力層には3つのニューロンを置きます。  \n",
    "これらのニューロンの出力はそれぞれが各品種に対応しており、最も出力の値が大きいニューロンの品種に花が分類されることになります。  \n",
    "2つの中間層にはとりあえずそれぞれ25個のニューロンを置きます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●学習に関する各種設定\n",
    "今回は、学習に関する各種設定を以下の通りにします。\n",
    "\n",
    "|||\n",
    "|:-:|:-:|\n",
    "| 中間層の活性化関数 | ReLU |\n",
    "| 出力層の活性化関数 | ソフトマックス関数 |\n",
    "| 損失関数 | 交差エントロピー誤差 |\n",
    "| 最適化アルゴリズム | 確率的勾配降下法 |\n",
    "| バッチサイズ | 8 |\n",
    "| 中間層のニューロン数 | 25 |\n",
    "|||\n",
    "\n",
    "これまでよりも深い層を持つニューラルネットワークを扱うので、勾配消失に対して頑強なReLUを中間層の活性化関数として使用します。  \n",
    "また、分類問題を扱うので、出力層の活性化関数にはソフトマックス関数を、損失関数には交差エントロピー誤差を用います。  \n",
    "そして、最適化アルゴリズムにはとりあえず最もシンプルな確率的勾配降下法を使います。  \n",
    "\n",
    "今回は、学習を安定させるために、ミニバッチ法を用いてバッチごとに重みとバイアスを更新します。その際のバッチサイズは8に設定します。  \n",
    "訓練データは1エポックごとにシャッフルされるので、ミニバッチには毎回ランダムなサンプルが含まれることになります。  \n",
    "\n",
    "上記のケースでは、訓練データのサンプル数は$150 / 2 = 75$なので、1エポックあたりの更新回数は$75 / 8 = 9.375$より端数を切り捨てて9回となります。  \n",
    "端数の分を学習に用いることも可能ですが、今回はコードをなるべくシンプルに保つため用いません。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●データの入手と前処理\n",
    "Irisデータセットは、scikit-learnという機械学習用のモジュールを用いて簡単に読み込むことができます。  \n",
    "scikit-learnはAnacondaに含まれているので、Anacondaを導入済みであれば特に何もしなくても使用することができます。  \n",
    "以下はscikit-learnを用いてIrisデータセットを読み込み、測定値と正解値を得るためのコードです。  \n",
    "測定値はニューラルネットワークの入力となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# -- Irisデータの読み込み --\n",
    "iris_data = datasets.load_iris()\n",
    "input_data = iris_data.data\n",
    "correct = iris_data.target\n",
    "n_data = len(correct)  # サンプル数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learnのdatasetsをimportすることにより、`load_iris()`でIrisデータセットを読み込むことができます。  \n",
    "測定値は`iris_data.data`に格納されているので、これを`input_data`に入れて入力データとします。  \n",
    "また、品種のインデックスは`iris_data.target`に格納されているので、これを`correct`に入れて正解とします。  \n",
    "この時点で、`input_data`及び`correct`の中身は以下の通りです。\n",
    "\n",
    "```\n",
    "[[ 5.1  3.5  1.4  0.2]\n",
    " [ 4.9  3.   1.4  0.2]\n",
    " [ 4.7  3.2  1.3  0.2]\n",
    " ・・・\n",
    " （中略）\n",
    " ・・・\n",
    " [ 5.9  3.   5.1  1.8]]\n",
    "```\n",
    "\n",
    "```\n",
    "[0 0 ...（中略）... 0 0 1 1 ...（中略）... 1 1 2 2 ...（中略）...2 2]\n",
    "```\n",
    "\n",
    "次に、入力データである測定値を標準化します。  \n",
    "標準化することにより、学習が安定し高速になります。  \n",
    "標準化されたデータを$z$、元のデータを$X$、元のデータの平均値を$\\mu$、元のデータの標準偏差を$\\sigma$とすると、標準化は次の式で表されます。\n",
    "\n",
    "$$ z = \\frac{X - \\mu}{\\sigma} $$\n",
    "\n",
    "元のデータの各値から平均値を引いて、標準偏差で割ることでデータの平均値は0、標準偏差は1になります。  \n",
    "この式を元にして、次のコードでIrisデータセットにおける各測定値の標準化を行うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 入力データを標準化する --\n",
    "ave_input = np.average(input_data, axis=0)\n",
    "std_input = np.std(input_data, axis=0)\n",
    "input_data = (input_data - ave_input) / std_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このコードでは、まずNumpyのaverage関数で測定値の平均値を計算します。  \n",
    "測定値には、Sepal length、Sepal width、Petal length、Petal widthの4種類がありますが、それぞれの種類ごとに平均をとるために、`axis=0`で平均の軸を設定します。  \n",
    "同様にして標準偏差も計算し、入力データを標準化します。  \n",
    "`ave_input`と`std_input`はベクトルですが`input_data`は行列なので、ここではブロードキャストを用いた計算が行われます。  \n",
    "\n",
    "次に、正解値をone-hot表現で表します。出力層のニューロン数が3なので、正解は以下の3通りのone-hot表現で表します。\n",
    "\n",
    "```\n",
    "[1 0 0]\n",
    "[0 1 0]\n",
    "[0 0 1]\n",
    "```\n",
    "\n",
    "Irisデータセットの品種インデックスを、one-hot表現に変換するコードは以下の通りです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 正解をone-hot表現にする --\n",
    "correct_data = np.zeros((n_data, 3))\n",
    "for i in range(n_data):\n",
    "    correct_data[i, correct[i]] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "このコードでは、Numpyのzeros関数で$n \\times 3$の行列を作っています。  \n",
    "そして、各花に対応する行の、品種のインデックスに対応する列の値を1に設定しています。  \n",
    "これにより、各花の品種がone-hot表現で表され、正解値になります。\n",
    "\n",
    "`input_data`の中には標準化された値が行列で格納されていますが、各行がそれぞれの花に対応し、各列が各種の測定値に対応します。  `correct_data`の各行も各花に対応し、各列は品種を表すone-hot表現になっています。  \n",
    "これらのデータ構造を、以下の図に示します。\n",
    "\n",
    "<img src=\"images/data_structure.png\">\n",
    "\n",
    "次に、これらのデータを訓練データとテストデータに分割します。  \n",
    "全てのデータを半分に分けて、それぞれ訓練データとテストデータにします。  \n",
    "これは、以下のコードで実装できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 訓練データとテストデータ --\n",
    "index = np.arange(n_data)\n",
    "index_train = index[index%2 == 0]\n",
    "index_test = index[index%2 != 0]\n",
    "\n",
    "input_train = input_data[index_train, :]  # 訓練 入力\n",
    "correct_train = correct_data[index_train, :]  # 訓練 正解\n",
    "input_test = input_data[index_test, :]  # テスト 入力\n",
    "correct_test = correct_data[index_test, :]  # テスト 正解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全部でn個のサンプルがあるのですが、Numpyのarrange関数により0からn-1までが値として格納された配列`index`を作ります。  \n",
    "そして、このうち2で割った余りが0なもの、すなわち偶数の値を`index_train`に格納して、2で割った余りが0でないのもの、すなわち奇数の値を`index_test`に格納します。  \n",
    "\n",
    "これらのインデックスとNumpyのスライス機能を用いて、`input_data`と`correct_data`を分割します。  \n",
    "これらの行列のうち、列のインデックスが`index_train`であるものは`input_train`と`correct_train`に、列のインデックスが`index_test`であるものは`input_test`と`correct_test`に格納します。  \n",
    "以上により、訓練データとテストデータを用意することができました。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
