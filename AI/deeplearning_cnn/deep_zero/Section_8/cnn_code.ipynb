{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNの実装\n",
    "cnnを実装し、手書き文字の認識を行います。  \n",
    "コードが長くなるので、いくつかに分けて掲載します。  \n",
    "コードを実行する際は、セルを上から順番に実行しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●データの準備\n",
    "まず、手書き文字の読み込みと前処理を行います。  \n",
    "入力データは標準化し、正解データはone-hot表現にします。  \n",
    "また、今回は全体の1/3をテストデータとし、残りを訓練データとします。  \n",
    "\n",
    "また、im2colとcol2imの関数を含むcnn_tools.pyというファイルをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from cnn_tools import im2col, col2im\n",
    "\n",
    "# -- 手書き文字データセットの読み込み --\n",
    "digits_data = datasets.load_digits()\n",
    "input_data = digits_data.data\n",
    "correct = digits_data.target\n",
    "n_data = len(correct)\n",
    "\n",
    "# -- 入力データの標準化 --\n",
    "ave_input = np.average(input_data)\n",
    "std_input = np.std(input_data)\n",
    "input_data = (input_data - ave_input) / std_input\n",
    "\n",
    "# -- 正解をone-hot表現に --\n",
    "correct_data = np.zeros((n_data, 10))\n",
    "for i in range(n_data):\n",
    "    correct_data[i, correct[i]] = 1.0\n",
    "\n",
    "# -- 訓練データとテストデータ --\n",
    "index = np.arange(n_data)\n",
    "index_train = index[index%3 != 0]\n",
    "index_test = index[index%3 == 0]\n",
    "\n",
    "input_train = input_data[index_train, :]  # 訓練 入力\n",
    "correct_train = correct_data[index_train, :]  # 訓練 正解\n",
    "input_test = input_data[index_test, :]  # テスト 入力\n",
    "correct_test = correct_data[index_test, :]  # テスト 正解\n",
    "\n",
    "n_train = input_train.shape[0]  # 訓練データのサンプル数\n",
    "n_test = input_test.shape[0]  # テストデータのサンプル数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●各設定\n",
    "学習の各設定を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 各設定値 --\n",
    "img_h = 8  # 入力画像の高さ\n",
    "img_w = 8  # 入力画像の幅\n",
    "img_ch = 1  # 入力画像のチャンネル数\n",
    "\n",
    "wb_width = 0.1  # 重みとバイアスの広がり具合\n",
    "eta = 0.01  # 学習係数\n",
    "epoch = 50\n",
    "batch_size = 8\n",
    "interval = 10  # 経過の表示間隔\n",
    "n_sample = 200  # 誤差計測のサンプル数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●畳み込み層、プーリング層の実装\n",
    "畳み込み層、プーリング層をクラスとして実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 畳み込み層 --\n",
    "class ConvLayer:\n",
    "    \n",
    "    # n_bt:バッチサイズ, x_ch:入力チャンネル数, x_h:入力画像高さ, x_w:入力画像幅\n",
    "    # n_flt:フィルタ数, flt_h:フィルタ高さ, flt_w:フィルタ幅\n",
    "    # stride:ストライド幅, pad:パディング幅\n",
    "    # y_ch:出力チャンネル数, y_h:出力高さ, y_w:出力幅\n",
    "    \n",
    "    def __init__(self, x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad):\n",
    "\n",
    "        # パラメータをまとめる\n",
    "        self.params = (x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad)\n",
    "        \n",
    "        # フィルタとバイアスの初期値\n",
    "        self.w = wb_width * np.random.randn(n_flt, x_ch, flt_h, flt_w)\n",
    "        self.b = wb_width * np.random.randn(1, n_flt)\n",
    "        \n",
    "        # 出力画像のサイズ\n",
    "        self.y_ch = n_flt  # 出力チャンネル数\n",
    "        self.y_h = (x_h - flt_h + 2*pad) // stride + 1  # 出力高さ\n",
    "        self.y_w = (x_w - flt_w + 2*pad) // stride + 1  # 出力幅\n",
    " \n",
    "        # AdaGrad用\n",
    "        self.h_w = np.zeros((n_flt, x_ch, flt_h, flt_w)) + 1e-8\n",
    "        self.h_b = np.zeros((1, n_flt)) + 1e-8\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n_bt = x.shape[0] \n",
    "        x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad = self.params\n",
    "        y_ch, y_h, y_w = self.y_ch, self.y_h, self.y_w\n",
    "        \n",
    "        # 入力画像とフィルタを行列に変換\n",
    "        self.cols = im2col(x, flt_h, flt_w, y_h, y_w, stride, pad)\n",
    "        self.w_col = self.w.reshape(n_flt, x_ch*flt_h*flt_w)\n",
    "        \n",
    "        # 出力の計算: 行列積、バイアスの加算、活性化関数\n",
    "        u = np.dot(self.w_col, self.cols).T + self.b\n",
    "        self.u = u.reshape(n_bt, y_h, y_w, y_ch).transpose(0, 3, 1, 2)\n",
    "        self.y = np.where(self.u <= 0, 0, self.u)\n",
    "    \n",
    "    def backward(self, grad_y):\n",
    "        n_bt = grad_y.shape[0]\n",
    "        x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad = self.params\n",
    "        y_ch, y_h, y_w = self.y_ch, self.y_h, self.y_w\n",
    "        \n",
    "        # delta\n",
    "        delta = grad_y * np.where(self.u <= 0, 0, 1)\n",
    "        delta = delta.transpose(0,2,3,1).reshape(n_bt*y_h*y_w, y_ch)\n",
    "        \n",
    "        # フィルタとバイアスの勾配\n",
    "        grad_w = np.dot(self.cols, delta)\n",
    "        self.grad_w = grad_w.T.reshape(n_flt, x_ch, flt_h, flt_w)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        \n",
    "        # 入力の勾配\n",
    "        grad_cols = np.dot(delta, self.w_col)\n",
    "        x_shape = (n_bt, x_ch, x_h, x_w)\n",
    "        self.grad_x = col2im(grad_cols.T, x_shape, flt_h, flt_w, y_h, y_w, stride, pad)\n",
    "        \n",
    "    def update(self, eta):\n",
    "        self.h_w += self.grad_w * self.grad_w\n",
    "        self.w -= eta / np.sqrt(self.h_w) * self.grad_w\n",
    "        \n",
    "        self.h_b += self.grad_b * self.grad_b\n",
    "        self.b -= eta / np.sqrt(self.h_b) * self.grad_b\n",
    "        \n",
    "# -- プーリング層 --\n",
    "class PoolingLayer:\n",
    "    \n",
    "    # n_bt:バッチサイズ, x_ch:入力チャンネル数, x_h:入力画像高さ, x_w:入力画像幅\n",
    "    # pool:プーリング領域のサイズ, pad:パディング幅\n",
    "    # y_ch:出力チャンネル数, y_h:出力高さ, y_w:出力幅\n",
    "    \n",
    "    def __init__(self, x_ch, x_h, x_w, pool, pad):\n",
    "        \n",
    "        # パラメータをまとめる\n",
    "        self.params = (x_ch, x_h, x_w, pool, pad)\n",
    "        \n",
    "        # 出力画像のサイズ\n",
    "        self.y_ch = x_ch  # 出力チャンネル数\n",
    "        self.y_h = x_h//pool if x_h%pool==0 else x_h//pool+1  # 出力高さ\n",
    "        self.y_w = x_w//pool if x_w%pool==0 else x_w//pool+1  # 出力幅\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n_bt = x.shape[0] \n",
    "        x_ch, x_h, x_w, pool, pad = self.params\n",
    "        y_ch, y_h, y_w = self.y_ch, self.y_h, self.y_w\n",
    "        \n",
    "        # 入力画像を行列に変換\n",
    "        cols = im2col(x, pool, pool, y_h, y_w, pool, pad)\n",
    "        cols = cols.T.reshape(n_bt*y_h*y_w*x_ch, pool*pool)\n",
    "        \n",
    "        # 出力の計算: Maxプーリング\n",
    "        y = np.max(cols, axis=1)\n",
    "        self.y = y.reshape(n_bt, y_h, y_w, x_ch).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        # 最大値のインデックスを保存\n",
    "        self.max_index = np.argmax(cols, axis=1)\n",
    "    \n",
    "    def backward(self, grad_y):\n",
    "        n_bt = grad_y.shape[0] \n",
    "        x_ch, x_h, x_w, pool, pad = self.params\n",
    "        y_ch, y_h, y_w = self.y_ch, self.y_h, self.y_w\n",
    "        \n",
    "        # 出力の勾配の軸を入れ替え\n",
    "        grad_y = grad_y.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        # 行列を作成し、各列の最大値であった要素にのみ出力の勾配を入れる\n",
    "        grad_cols = np.zeros((pool*pool, grad_y.size))\n",
    "        grad_cols[self.max_index.reshape(-1), np.arange(grad_y.size)] = grad_y.reshape(-1) \n",
    "        grad_cols = grad_cols.reshape(pool, pool, n_bt, y_h, y_w, y_ch)\n",
    "        grad_cols = grad_cols.transpose(5,0,1,2,3,4) \n",
    "        grad_cols = grad_cols.reshape( y_ch*pool*pool, n_bt*y_h*y_w)\n",
    "\n",
    "        # 入力の勾配\n",
    "        x_shape = (n_bt, x_ch, x_h, x_w)\n",
    "        self.grad_x = col2im(grad_cols, x_shape, pool, pool, y_h, y_w, pool, pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●全結合層の実装\n",
    "全結合層（中間層、出力層）をクラスとして実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 全結合層の継承元 --\n",
    "class BaseLayer:\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = wb_width * np.random.randn(n_upper, n)\n",
    "        self.b = wb_width * np.random.randn(n)\n",
    "\n",
    "        self.h_w = np.zeros(( n_upper, n)) + 1e-8\n",
    "        self.h_b = np.zeros(n) + 1e-8\n",
    "        \n",
    "    def update(self, eta):\n",
    "        self.h_w += self.grad_w * self.grad_w\n",
    "        self.w -= eta / np.sqrt(self.h_w) * self.grad_w\n",
    "        \n",
    "        self.h_b += self.grad_b * self.grad_b\n",
    "        self.b -= eta / np.sqrt(self.h_b) * self.grad_b\n",
    "        \n",
    "# -- 全結合 中間層 --\n",
    "class MiddleLayer(BaseLayer):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.where(self.u <= 0, 0, self.u)\n",
    "    \n",
    "    def backward(self, grad_y):\n",
    "        delta = grad_y * np.where(self.u <= 0, 0, 1)\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        \n",
    "        self.grad_x = np.dot(delta, self.w.T) \n",
    "\n",
    "# -- 全結合 出力層 --\n",
    "class OutputLayer(BaseLayer):     \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.exp(u)/np.sum(np.exp(u), axis=1).reshape(-1, 1)\n",
    "\n",
    "    def backward(self, t):\n",
    "        delta = self.y - t\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        \n",
    "        self.grad_x = np.dot(delta, self.w.T) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●CNNの構築\n",
    "以下のコードでCNNを構築します。  \n",
    "順伝播においてプーリング層の出力を全結合層へ入力する際は、プーリング層の出力である4次元配列を、全結合層の入力である2次元配列に変換します。  \n",
    "逆伝播の場合は、反対に2次元配列を4次元配列に変換します。  \n",
    "\n",
    "畳み込み層では、ストライドを1に、パディングの幅を1に設定します。  \n",
    "パディングを行うのは畳み込みにより画像が小さくなり過ぎるのを防ぐためです。  \n",
    "`forward_sample`メソッドは、サンプルの誤差や正解率の測定に用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 各層の初期化 --\n",
    "cl_1 = ConvLayer(img_ch, img_h, img_w, 10, 3, 3, 1, 1)\n",
    "pl_1 = PoolingLayer(cl_1.y_ch, cl_1.y_h, cl_1.y_w, 2, 0)\n",
    "\n",
    "n_fc_in = pl_1.y_ch * pl_1.y_h * pl_1.y_w\n",
    "ml_1 = MiddleLayer(n_fc_in, 100)\n",
    "ol_1 = OutputLayer(100, 10)\n",
    "\n",
    "# -- 順伝播 --\n",
    "def forward_propagation(x):\n",
    "    n_bt = x.shape[0]\n",
    "    \n",
    "    images = x.reshape(n_bt, img_ch, img_h, img_w)\n",
    "    cl_1.forward(images)\n",
    "    pl_1.forward(cl_1.y)\n",
    "    \n",
    "    fc_input = pl_1.y.reshape(n_bt, -1)   \n",
    "    ml_1.forward(fc_input)\n",
    "    ol_1.forward(ml_1.y)\n",
    "\n",
    "# -- 逆伝播 --\n",
    "def backpropagation(t):\n",
    "    n_bt = t.shape[0]\n",
    "    \n",
    "    ol_1.backward(t)\n",
    "    ml_1.backward(ol_1.grad_x)\n",
    "    \n",
    "    grad_img = ml_1.grad_x.reshape(n_bt, pl_1.y_ch, pl_1.y_h, pl_1.y_w)\n",
    "    pl_1.backward(grad_img)\n",
    "    cl_1.backward(pl_1.grad_x)\n",
    "\n",
    "# -- 重みとバイアスの更新 --\n",
    "def uppdate_wb():\n",
    "    cl_1.update(eta)\n",
    "    ml_1.update(eta)\n",
    "    ol_1.update(eta)\n",
    "\n",
    "# -- 誤差を計算 --\n",
    "def get_error(t, batch_size):\n",
    "    return -np.sum(t * np.log(ol_1.y + 1e-7)) / batch_size # 交差エントロピー誤差\n",
    "\n",
    "# -- サンプルを順伝播 --\n",
    "def forward_sample(inp, correct, n_sample):\n",
    "    index_rand = np.arange(len(correct))\n",
    "    np.random.shuffle(index_rand) \n",
    "    index_rand = index_rand[:n_sample]\n",
    "    x = inp[index_rand, :]\n",
    "    t = correct[index_rand, :]\n",
    "    forward_propagation(x)\n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●CNNによる学習\n",
    "学習を行います。  \n",
    "1エポックごとに、訓練誤差とテスト誤差を計測し記録します。  \n",
    "また、`interval`の間隔で途中経過を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 誤差の記録用 --\n",
    "train_error_x = []\n",
    "train_error_y = []\n",
    "test_error_x = []\n",
    "test_error_y = []\n",
    "\n",
    "# -- 学習と経過の記録 --\n",
    "n_batch = n_train // batch_size\n",
    "for i in range(epoch):\n",
    "\n",
    "    # -- 誤差の計測 -- \n",
    "    x, t = forward_sample(input_train, correct_train, n_sample)\n",
    "    error_train = get_error(t, n_sample)\n",
    "    \n",
    "    x, t = forward_sample(input_test, correct_test, n_sample) \n",
    "    error_test = get_error(t, n_sample)\n",
    "    \n",
    "    # -- 誤差の記録 -- \n",
    "    train_error_x.append(i)\n",
    "    train_error_y.append(error_train) \n",
    "    test_error_x.append(i)\n",
    "    test_error_y.append(error_test) \n",
    "    \n",
    "    # -- 経過の表示 --\n",
    "    if i%interval == 0:\n",
    "        print(\"Epoch:\" + str(i) + \"/\" + str(epoch),\n",
    "              \"Error_train:\" + str(error_train),\n",
    "              \"Error_test:\" + str(error_test))\n",
    "    \n",
    "    # -- 学習 -- \n",
    "    index_rand = np.arange(n_train)\n",
    "    np.random.shuffle(index_rand)   \n",
    "    for j in range(n_batch):\n",
    "        \n",
    "        mb_index = index_rand[j*batch_size : (j+1)*batch_size]\n",
    "        x = input_train[mb_index, :]\n",
    "        t = correct_train[mb_index, :]\n",
    "\n",
    "        forward_propagation(x)\n",
    "        backpropagation(t)        \n",
    "        uppdate_wb() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●結果の表示\n",
    "最後に、学習の結果を表示します。  \n",
    "訓練誤差とテスト誤差の記録をグラフで表示し、全ての訓練データとテストデータを使ってそれぞれの正解率を測定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 誤差の記録をグラフ表示 -- \n",
    "plt.plot(train_error_x, train_error_y, label=\"Train\")\n",
    "plt.plot(test_error_x, test_error_y, label=\"Test\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# -- 正解率の測定 -- \n",
    "x, t = forward_sample(input_train, correct_train, n_train) \n",
    "count_train = np.sum(np.argmax(ol_1.y, axis=1) == np.argmax(t, axis=1))\n",
    "\n",
    "x, t = forward_sample(input_test, correct_test, n_test) \n",
    "count_test = np.sum(np.argmax(ol_1.y, axis=1) == np.argmax(t, axis=1))\n",
    "\n",
    "print(\"Accuracy Train:\", str(count_train/n_train*100) + \"%\",\n",
    "      \"Accuracy Test:\", str(count_test/n_test*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練誤差、テスト誤差共に収束しており、過学習が生じている様子は見られません。  \n",
    "50エポックの学習で、訓練データの正解率、テストデータの正解率ともに高いものになりました。  \n",
    "なお、乱数を使用しているため正解率には多少のばらつきがあります。    \n",
    "\n",
    "正解したテストデータのサンプルと、不正解だったテストデータのサンプルを見てみましょう。  \n",
    "以下の図に正解した画像と不正解だった画像を並べます。  \n",
    "上段が正解の例で、下段が不正解の例です。  \n",
    "\n",
    "<img src=\"images/correct_or_not.png\">\n",
    "\n",
    "矢印の左が正解です。  \n",
    "不正解だった画像は人の目でも間違いそうなものが多いですね。  \n",
    "\n",
    "ここで、畳み込み層のフィルタと出力を可視化してみましょう。  \n",
    "以下の図は学習前のフィルタと学習後のフィルタを画像化し並べたものです。\n",
    "\n",
    "<img src=\"images/filter_visulalization.png\">\n",
    "\n",
    "学習前のフィルタはランダムな値ですが、学習により各フィルタが様々な特徴を捉えるように変化しています。  \n",
    "\n",
    "以下の図は学習後の畳み込み層の出力をフィルタごとに並べたものです。\n",
    "\n",
    "<img src=\"images/conv_output.png\">\n",
    "\n",
    "各出力は、元の画像の様々な特徴が抽出されたものになっています。  \n",
    "畳み込み層がしっかりと機能していることが確かめられますね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最後に\n",
    "「ディープラーニング : Pythonでゼロから構築し学ぶ人工知能（AI）と深層学習の原理」、最後までおつきあいいただき有難うございました。  \n",
    "我々はとても面白時代に生きています。  \n",
    "複雑さが複雑さを生むことで技術は指数関数的な進歩を続けており、ディープラーニングはこのような時代を象徴するような技術であるとも言えます。  \n",
    "ディープラーニングはスキルとして役に立つだけではなく、現在と未来を学ぶための教養として大きな意義があります。  \n",
    "本コースが、皆さんの今後に何らかの形でお役に立てば、講師として嬉しい限りです。  \n",
    "\n",
    "我妻幸長（Yukinaga Azuma）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
