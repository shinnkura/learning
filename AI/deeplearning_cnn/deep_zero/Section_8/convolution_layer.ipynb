{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込み層の実装\n",
    "畳み込み層の具体的な実装方法を解説します。  \n",
    "順伝播、逆伝播のコードを実装していきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●畳み込み層のクラス\n",
    "畳み込み層は、以下のようにクラスとして実装します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- 畳み込み層 --\n",
    "class ConvLayer:\n",
    "    \n",
    "    # n_bt:バッチサイズ, x_ch:入力チャンネル数, x_h:入力画像高さ, x_w:入力画像幅\n",
    "    # n_flt:フィルタ数, flt_h:フィルタ高さ, flt_w:フィルタ幅\n",
    "    # stride:ストライド幅, pad:パディング幅\n",
    "    # y_ch:出力チャンネル数, y_h:出力高さ, y_w:出力幅\n",
    "    \n",
    "    def __init__(self, x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad):\n",
    "\n",
    "        # パラメータをまとめる\n",
    "        self.params = (x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad)\n",
    "        \n",
    "        # フィルタとバイアスの初期値\n",
    "        self.w = wb_width * np.random.randn(n_flt, x_ch, flt_h, flt_w)\n",
    "        self.b = wb_width * np.random.randn(1, n_flt)\n",
    "        \n",
    "        # 出力画像のサイズ\n",
    "        self.y_ch = n_flt  # 出力チャンネル数\n",
    "        self.y_h = (x_h - flt_h + 2*pad) // stride + 1  # 出力高さ\n",
    "        self.y_w = (x_w - flt_w + 2*pad) // stride + 1  # 出力幅\n",
    "\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__init__メソッドでは、変更したり外部からアクセスしたりする必要のないパラメータを`self.params`にまとめています。  \n",
    "また、フィルタ（`self.w`）とバイアス（`b`）の初期値を設定しています。  \n",
    "フィルタはニューロンの重みと同じように扱うことができるため、変数名は`w`としています。\n",
    "\n",
    "出力画像のチャンネル数、高さ、幅は、外部からアクセス可能にするために`self`が付けられています。  \n",
    "このクラスに、メソッドとして順伝播と逆伝播を実装します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●畳み込み層の順伝播\n",
    "畳み込み層の順伝播を図で表すと、以下のようになります。\n",
    "\n",
    "<img src=\"images/conv_forward.png\">\n",
    "\n",
    "この図を踏まえて、畳み込み層における順伝播を以下のようにメソッドとして実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def forward(self, x):\n",
    "        n_bt = x.shape[0] \n",
    "        x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad = self.params\n",
    "        y_ch, y_h, y_w = self.y_ch, self.y_h, self.y_w\n",
    "        \n",
    "        # 入力画像とフィルタを行列に変換\n",
    "        self.cols = im2col(x, flt_h, flt_w, y_h, y_w, stride, pad)\n",
    "        self.w_col = self.w.reshape(n_flt, x_ch*flt_h*flt_w)\n",
    "        \n",
    "        # 出力の計算: 行列積、バイアスの加算、活性化関数\n",
    "        u = np.dot(self.w_col, self.cols).T + self.b\n",
    "        self.u = u.reshape(n_bt, y_h, y_w, y_ch).transpose(0, 3, 1, 2)\n",
    "        self.y = np.where(self.u <= 0, 0, self.u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`self`が付いている変数は、他のメソッドと共有するインスタンス変数です。  \n",
    "\n",
    "メソッド内では、最初にim2colで入力画像を行列`self.w_col`に変換します。  \n",
    "本セクションは、あらかじめ用意されたim2colのための関数を使用します。  \n",
    "この関数には、入力画像、フィルタ高さ、幅、出力画像の高さ、幅、ストライドの幅、パディングの幅を渡します。  \n",
    "そして、im2colにより変換された行列を返り値として得ることができます。  \n",
    "\n",
    "また、フィルタはreshapeにより行列`self.w_col`に変換しておきます。  \n",
    "\n",
    "`self.w_col`と`self.cols`の行列積をNumpyのdot関数により計算します。\n",
    "この行列積の結果を、バイアスと列数を合わせるために転置した上で、バイアスを加えて`u`とします。 \n",
    "\n",
    "そして、reshapeとtransposeにより形状を整えて`self.u`とします。  \n",
    "transposeはNumPyの関数で、行列の軸を入れ替えることができます。  \n",
    "これにより、バッチやチャンネル、画像の幅や高さなどの順番を配列内で入れ替えることができます。  \n",
    "transposeについて詳しく知りたい方は、セルに簡単なコードを書いて配列の軸を入れ替えてみるとtransposeの特性が把握できるかと思います。  \n",
    "これにより、`self.u`は入力画像と同じようにバッチとチャンネルに対応することになります。  \n",
    "\n",
    "最後に、活性化関数でこの`self.u`を処理して、順伝播の出力とします。  \n",
    "活性化関数にはReLUを使います。  \n",
    "\n",
    "以上が順伝播の実装になりますが、フィルタを重みに置き換えれば、通常のニューラルネットワークの層における順伝播に似ているかと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●畳み込み層の逆伝播\n",
    "畳み込み層においては、以下の図のようにして各勾配を求めることができます。\n",
    "\n",
    "<img src=\"images/conv_backward.png\">\n",
    "\n",
    "まず$\\delta$を出力の勾配と活性化関数の微分をかけて求めます。    \n",
    "そして、フィルタの勾配をcolsと$\\delta$の行列積により求めます。  \n",
    "バイアスの勾配は$\\delta$そのままです。  \n",
    "\n",
    "そして、colsの勾配をdeltaとフィルタの行列積で求めます。    \n",
    "このcolsの勾配を、col2imにより入力の勾配に変換します。    \n",
    "\n",
    "col2im以外は通常のニューラルネットワークにおける逆伝播と似ていますね。  \n",
    "この図を踏まえて、逆伝播を以下のようにメソッドとして実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def backward(self, grad_y):\n",
    "        n_bt = grad_y.shape[0]\n",
    "        x_ch, x_h, x_w, n_flt, flt_h, flt_w, stride, pad = self.params\n",
    "        y_ch, y_h, y_w = self.y_ch, self.y_h, self.y_w\n",
    "        \n",
    "        # delta\n",
    "        delta = grad_y * np.where(self.u <= 0, 0, 1)\n",
    "        delta = delta.transpose(0,2,3,1).reshape(n_bt*y_h*y_w, y_ch)\n",
    "        \n",
    "        # フィルタとバイアスの勾配\n",
    "        grad_w = np.dot(self.cols, delta)\n",
    "        self.grad_w = grad_w.T.reshape(n_flt, x_ch, flt_h, flt_w)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        \n",
    "        # 入力の勾配\n",
    "        grad_cols = np.dot(delta, self.w_col)\n",
    "        x_shape = (n_bt, x_ch, x_h, x_w)\n",
    "        self.grad_x = col2im(grad_cols.T, x_shape, flt_h, flt_w, y_h, y_w, stride, pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このメソッドでは、出力の勾配（下の層の入力の勾配）を引数として受け取ります。  \n",
    "これに活性化関数の微分形をかけて`delta`とします。  \n",
    "今回は、ReLUの微分形をかけています。  \n",
    "その上で、transposeとreshapeにより、`delta`を行列に変換します。  \n",
    "\n",
    "次に、フィルタとバイアスの勾配を求めます。  \n",
    "フィルタの勾配を求めるためには、まず`self.cols`と`delta`の行列積を求めます。   \n",
    "この`grad_w`を、転置し、reshapeすることでフィルタの形状に合わせます。  \n",
    "これにより、フィルタの勾配`self.grad_w`を求めることができます。  \n",
    "バイアスの勾配は、`delta`の各列がフィルタに対応しているので、列ごとの総和により求めます。  \n",
    "\n",
    "最後に、入力の勾配を求めます。  \n",
    "そのためにまず、`delta`と順伝播の際に求めた`self.w_col`の行列積によりcolsの勾配を求めます。\n",
    "\n",
    "この行列を転置したものは`self.cols`と同じ形状になります。  \n",
    "これをcol2imで画像の形状に変換し入力の勾配`self.grad_x`とします。  \n",
    "本セクションは、あらかじめ用意されたcol2imのための関数を使用します。  \n",
    "この関数には、変換前の行列、入力画像の形状、フィルタ高さ、幅、出力画像の高さ、幅、ストライドの幅、パディングの幅を渡します。  \n",
    "この入力の勾配`self.grad_x`が、上の層に伝播します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
