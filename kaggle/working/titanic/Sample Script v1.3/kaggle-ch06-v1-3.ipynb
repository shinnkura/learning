{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":207.333379,"end_time":"2024-02-14T12:58:24.381445","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-14T12:54:57.048066","version":"2.5.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"b41d30f1","cell_type":"markdown","source":"# 2024/12/19更新\n- 書籍発売後にライブラリのバージョンアップが生じたため、書籍のコードが一部動作しなくなりました\n- このため、書籍のコードが動作するようにコードを一部変更\n    - 変更を最小化するため、基本的には書籍に合わせてライブラリをダウングレード\n    - 名称変更となったライブラリは最新のライブラリ名に変更","metadata":{"papermill":{"duration":0.025574,"end_time":"2024-02-14T12:55:00.212684","exception":false,"start_time":"2024-02-14T12:55:00.187110","status":"completed"},"tags":[]}},{"id":"62ef762c","cell_type":"code","source":"# 引数が大きく変更されているため、ダウングレードで対応\n# 最初に実行してください。\n!pip install pandas==1.3.5\n!pip install lightgbm==3.3.1\n!pip install scikit-learn==1.0.2\n!pip install numba==0.58.0  # 2024/12/19追加\n\n# なお、LightGBMの最新版ではCallbackが使われており、過去バージョンと大きく書き方が変化。最新版を使い方を知りたい場合は公式ページを参照してください。\n# https://lightgbm.readthedocs.io/en/latest/index.html","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:38:34.128660Z","iopub.execute_input":"2024-12-19T08:38:34.129073Z","iopub.status.idle":"2024-12-19T08:39:19.359365Z","shell.execute_reply.started":"2024-12-19T08:38:34.129039Z","shell.execute_reply":"2024-12-19T08:39:19.358046Z"},"papermill":{"duration":64.443102,"end_time":"2024-02-14T12:56:04.682340","exception":false,"start_time":"2024-02-14T12:55:00.239238","status":"completed"},"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting pandas==1.3.5\n  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5) (2024.2)\nRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5) (1.26.4)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.5) (1.16.0)\nDownloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: pandas\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.1.4\n    Uninstalling pandas-2.1.4:\n      Successfully uninstalled pandas-2.1.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\narviz 0.19.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\nbigframes 1.17.0 requires pandas>=1.5.3, but you have pandas 1.3.5 which is incompatible.\ncudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.3.5 which is incompatible.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\ndask-expr 1.1.21 requires pandas>=2, but you have pandas 1.3.5 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\ngeopandas 0.14.4 requires pandas>=1.4.0, but you have pandas 1.3.5 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.3.5 which is incompatible.\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 18.1.0 which is incompatible.\nlibpysal 4.9.2 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\nmizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.3.5 which is incompatible.\npandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.3.5 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\nstatsmodels 0.14.3 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\nvisions 0.7.6 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\nxarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pandas-1.3.5\nCollecting lightgbm==3.3.1\n  Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl.metadata (15 kB)\nRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.1) (0.44.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.1) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.1) (1.13.1)\nRequirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.1) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.3.1) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.3.1) (3.5.0)\nDownloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lightgbm\n  Attempting uninstall: lightgbm\n    Found existing installation: lightgbm 4.5.0\n    Uninstalling lightgbm-4.5.0:\n      Successfully uninstalled lightgbm-4.5.0\nSuccessfully installed lightgbm-3.3.1\nCollecting scikit-learn==1.0.2\n  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.26.4)\nRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.13.1)\nRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2) (3.5.0)\nDownloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 1.17.0 requires pandas>=1.5.3, but you have pandas 1.3.5 which is incompatible.\nbigframes 1.17.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\nwoodwork 0.31.0 requires scikit-learn>=1.1.0, but you have scikit-learn 1.0.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikit-learn-1.0.2\nCollecting numba==0.58.0\n  Downloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\nCollecting llvmlite<0.42,>=0.41.0dev0 (from numba==0.58.0)\n  Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\nCollecting numpy<1.26,>=1.21 (from numba==0.58.0)\n  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nDownloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy, llvmlite, numba\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: llvmlite\n    Found existing installation: llvmlite 0.43.0\n    Uninstalling llvmlite-0.43.0:\n      Successfully uninstalled llvmlite-0.43.0\n  Attempting uninstall: numba\n    Found existing installation: numba 0.60.0\n    Uninstalling numba-0.60.0:\n      Successfully uninstalled numba-0.60.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\narviz 0.19.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\nbigframes 1.17.0 requires pandas>=1.5.3, but you have pandas 1.3.5 which is incompatible.\nbigframes 1.17.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.0.2 which is incompatible.\ncudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.3.5 which is incompatible.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\ngeopandas 0.14.4 requires pandas>=1.4.0, but you have pandas 1.3.5 which is incompatible.\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 18.1.0 which is incompatible.\nlibpysal 4.9.2 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\nmizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.3.5 which is incompatible.\npandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.25.2 which is incompatible.\nplotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.3.5 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\nstatsmodels 0.14.3 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\nvisions 0.7.6 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\nwoodwork 0.31.0 requires scikit-learn>=1.1.0, but you have scikit-learn 1.0.2 which is incompatible.\nxarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed llvmlite-0.41.1 numba-0.58.0 numpy-1.25.2\n","output_type":"stream"}],"execution_count":1},{"id":"761861f0-175b-40f0-ac53-3279c80426d6","cell_type":"code","source":"# 2024/12/19追加\n# ここで一度再起動してください。下記の２つのいずれかを実行。 \n#   - 方法1: 下記コードを実行するとメッセージボックスが表示されるので、「OK」ボタンを押す\n#   - 方法2: メニューの「Run」から「Restart & clear cel outputs」を選択して再起動\n\nimport IPython\nIPython.Application.instance().kernel.do_shutdown(restart=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T08:39:19.360875Z","iopub.execute_input":"2024-12-19T08:39:19.361173Z","iopub.status.idle":"2024-12-19T08:39:19.369599Z","shell.execute_reply.started":"2024-12-19T08:39:19.361149Z","shell.execute_reply":"2024-12-19T08:39:19.368295Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"{'status': 'ok', 'restart': True}"},"metadata":{}}],"execution_count":2},{"id":"dc83c998","cell_type":"markdown","source":"# Kaggleで磨く 機械学習の実践力\n# 第6章 モデルチューニング","metadata":{"papermill":{"duration":0.03207,"end_time":"2024-02-14T12:56:04.748098","exception":false,"start_time":"2024-02-14T12:56:04.716028","status":"completed"},"tags":[]}},{"id":"1fca4315","cell_type":"markdown","source":"# 6.1 LightGBMのハイパーパラメータのチューニング\n## 6.1.2 ハイパーパラメータの自動チューニング","metadata":{"papermill":{"duration":0.031524,"end_time":"2024-02-14T12:56:04.811162","exception":false,"start_time":"2024-02-14T12:56:04.779638","status":"completed"},"tags":[]}},{"id":"85d1788e","cell_type":"markdown","source":"#### スクリプト: ライブラリのインポート (スクリプト4-1の再掲)","metadata":{"papermill":{"duration":0.031239,"end_time":"2024-02-14T12:56:04.874150","exception":false,"start_time":"2024-02-14T12:56:04.842911","status":"completed"},"tags":[]}},{"id":"564a0837","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport gc\n\n# 分布確認\n# import pandas_profiling as pdp\nimport ydata_profiling as pdp # ライブラリ名称が変更になったため\n\n# 可視化\nimport matplotlib.pyplot as plt\n\n# 前処理\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n\n# バリデーション\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GroupKFold\n\n# 評価指標\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n\n# モデリング: lightgbm\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:06.565605Z","iopub.execute_input":"2024-12-19T08:40:06.566062Z","iopub.status.idle":"2024-12-19T08:40:11.268045Z","shell.execute_reply.started":"2024-12-19T08:40:06.566030Z","shell.execute_reply":"2024-12-19T08:40:11.266995Z"},"papermill":{"duration":8.437287,"end_time":"2024-02-14T12:56:13.344484","exception":false,"start_time":"2024-02-14T12:56:04.907197","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":1},{"id":"793f5ce7","cell_type":"markdown","source":"#### スクリプト: ファイルの読み込み (スクリプト4-2の再掲)","metadata":{"papermill":{"duration":0.032342,"end_time":"2024-02-14T12:56:13.411048","exception":false,"start_time":"2024-02-14T12:56:13.378706","status":"completed"},"tags":[]}},{"id":"994556f8","cell_type":"code","source":"df_train = pd.read_csv(\"../input/titanic/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:11.269275Z","iopub.execute_input":"2024-12-19T08:40:11.269863Z","iopub.status.idle":"2024-12-19T08:40:11.284398Z","shell.execute_reply.started":"2024-12-19T08:40:11.269833Z","shell.execute_reply":"2024-12-19T08:40:11.282998Z"},"papermill":{"duration":0.052107,"end_time":"2024-02-14T12:56:13.495709","exception":false,"start_time":"2024-02-14T12:56:13.443602","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":2},{"id":"9832187c","cell_type":"markdown","source":"#### スクリプト: データセット作成 (スクリプト4-8の再掲)","metadata":{"papermill":{"duration":0.031195,"end_time":"2024-02-14T12:56:13.560865","exception":false,"start_time":"2024-02-14T12:56:13.529670","status":"completed"},"tags":[]}},{"id":"2638d9e4","cell_type":"code","source":"x_train, y_train, id_train = df_train[[\"Pclass\", \"Fare\"]], \\\n                             df_train[[\"Survived\"]], \\\n                             df_train[[\"PassengerId\"]]\nprint(x_train.shape, y_train.shape, id_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:11.286399Z","iopub.execute_input":"2024-12-19T08:40:11.286768Z","iopub.status.idle":"2024-12-19T08:40:11.318298Z","shell.execute_reply.started":"2024-12-19T08:40:11.286729Z","shell.execute_reply":"2024-12-19T08:40:11.316983Z"},"papermill":{"duration":0.047684,"end_time":"2024-02-14T12:56:13.640210","exception":false,"start_time":"2024-02-14T12:56:13.592526","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"(891, 2) (891, 1) (891, 1)\n","output_type":"stream"}],"execution_count":3},{"id":"2f268078","cell_type":"markdown","source":"#### スクリプト6-1: optunaのインポート","metadata":{"papermill":{"duration":0.03322,"end_time":"2024-02-14T12:56:13.775620","exception":false,"start_time":"2024-02-14T12:56:13.742400","status":"completed"},"tags":[]}},{"id":"8e719dc7","cell_type":"code","source":"import optuna","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:11.319727Z","iopub.execute_input":"2024-12-19T08:40:11.320023Z","iopub.status.idle":"2024-12-19T08:40:11.647483Z","shell.execute_reply.started":"2024-12-19T08:40:11.319999Z","shell.execute_reply":"2024-12-19T08:40:11.646171Z"},"papermill":{"duration":1.417912,"end_time":"2024-02-14T12:56:15.225511","exception":false,"start_time":"2024-02-14T12:56:13.807599","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"id":"77e20ad5","cell_type":"markdown","source":"#### スクリプト6-2: 目的関数の定義","metadata":{"papermill":{"duration":0.03098,"end_time":"2024-02-14T12:56:15.288394","exception":false,"start_time":"2024-02-14T12:56:15.257414","status":"completed"},"tags":[]}},{"id":"246fa8f9","cell_type":"code","source":"# 探索しないハイパーパラメータ\nparams_base = {\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"binary\",\n    \"metric\": \"auc\",\n    \"learning_rate\": 0.02,\n    'n_estimators': 100000,\n    \"bagging_freq\": 1,\n    \"seed\": 123,\n}\n\ndef objective(trial):\n    # 探索するハイパーパラメータ\n    params_tuning = {\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 256),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 200),\n        \"min_sum_hessian_in_leaf\": trial.suggest_float(\"min_sum_hessian_in_leaf\", 1e-5, 1e-2, log=True),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.5, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-2, 1e2, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-2, 1e2, log=True),\n    }\n    params_tuning.update(params_base)\n    \n    # モデル学習・評価\n    list_metrics = []\n    cv = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(x_train, y_train))\n    for nfold in np.arange(5):\n        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n        x_tr, y_tr = x_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n        x_va, y_va = x_train.loc[idx_va, :], y_train.loc[idx_va, :]\n        model = lgb.LGBMClassifier(**params_tuning)\n        model.fit(x_tr,\n                  y_tr,\n                  eval_set=[(x_tr,y_tr), (x_va,y_va)],\n                  early_stopping_rounds=100,\n                  verbose=0,\n                 )\n#         # 2024/02/14環境で動かしたい場合はこのコードを利用してください。\n#         model.fit(x_tr,\n#                   y_tr,\n#                   eval_set=[(x_tr,y_tr), (x_va,y_va)],\n#                   callbacks=[\n#                       lgb.early_stopping(stopping_rounds=100, verbose=True),\n#                       lgb.log_evaluation(0),\n#                   ],\n#                  )\n        \n        y_va_pred = model.predict_proba(x_va)[:,1]\n        metric_va = accuracy_score(y_va, np.where(y_va_pred>=0.5, 1, 0))\n        list_metrics.append(metric_va)\n    \n    # 評価値の計算\n    metrics = np.mean(list_metrics)\n    \n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:11.648455Z","iopub.execute_input":"2024-12-19T08:40:11.648762Z","iopub.status.idle":"2024-12-19T08:40:11.659274Z","shell.execute_reply.started":"2024-12-19T08:40:11.648737Z","shell.execute_reply":"2024-12-19T08:40:11.657743Z"},"papermill":{"duration":0.059926,"end_time":"2024-02-14T12:56:15.380778","exception":false,"start_time":"2024-02-14T12:56:15.320852","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"id":"7ab36e22","cell_type":"markdown","source":"#### スクリプト6-3: 最適化処理（探索の実行）","metadata":{"papermill":{"duration":0.03115,"end_time":"2024-02-14T12:56:15.453203","exception":false,"start_time":"2024-02-14T12:56:15.422053","status":"completed"},"tags":[]}},{"id":"2b06c857","cell_type":"code","source":"sampler = optuna.samplers.TPESampler(seed=123)\nstudy = optuna.create_study(sampler=sampler, direction=\"maximize\")\nstudy.optimize(objective, n_trials=30)","metadata":{"collapsed":true,"execution":{"iopub.status.busy":"2024-12-19T08:40:11.660427Z","iopub.execute_input":"2024-12-19T08:40:11.660742Z","iopub.status.idle":"2024-12-19T08:40:26.142802Z","shell.execute_reply.started":"2024-12-19T08:40:11.660716Z","shell.execute_reply":"2024-12-19T08:40:26.141964Z"},"jupyter":{"outputs_hidden":true},"papermill":{"duration":60.689396,"end_time":"2024-02-14T12:57:16.174579","exception":false,"start_time":"2024-02-14T12:56:15.485183","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"[I 2024-12-19 08:40:11,683] A new study created in memory with name: no-name-85c65b98-595c-482e-95ec-c8f621ac170d\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:12,329] Trial 0 finished with value: 0.664478061640826 and parameters: {'num_leaves': 181, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 4.792414358623587e-05, 'feature_fraction': 0.7756573845414456, 'bagging_fraction': 0.8597344848927815, 'lambda_l1': 0.492522233779106, 'lambda_l2': 83.76388146302445}. Best is trial 0 with value: 0.664478061640826.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:12,736] Trial 1 finished with value: 0.6712196346745339 and parameters: {'num_leaves': 178, 'min_data_in_leaf': 99, 'min_sum_hessian_in_leaf': 0.00015009027543233888, 'feature_fraction': 0.6715890080754348, 'bagging_fraction': 0.8645248536920208, 'lambda_l1': 0.567922374174008, 'lambda_l2': 0.01732652966363563}. Best is trial 1 with value: 0.6712196346745339.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:13,107] Trial 2 finished with value: 0.65762350134957 and parameters: {'num_leaves': 107, 'min_data_in_leaf': 149, 'min_sum_hessian_in_leaf': 3.52756635172055e-05, 'feature_fraction': 0.5877258780737462, 'bagging_fraction': 0.7657756869209191, 'lambda_l1': 1.3406343673102123, 'lambda_l2': 3.4482904089131434}. Best is trial 1 with value: 0.6712196346745339.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:13,460] Trial 3 finished with value: 0.6722302429226037 and parameters: {'num_leaves': 219, 'min_data_in_leaf': 146, 'min_sum_hessian_in_leaf': 0.0006808799287054756, 'feature_fraction': 0.8612216912851107, 'bagging_fraction': 0.6614794569265892, 'lambda_l1': 0.2799978022399009, 'lambda_l2': 0.08185645330667264}. Best is trial 3 with value: 0.6722302429226037.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:13,822] Trial 4 finished with value: 0.668972443663298 and parameters: {'num_leaves': 81, 'min_data_in_leaf': 128, 'min_sum_hessian_in_leaf': 1.889360449174926e-05, 'feature_fraction': 0.7168505863397641, 'bagging_fraction': 0.7154313816648219, 'lambda_l1': 0.9434967110751797, 'lambda_l2': 0.5050346330980694}. Best is trial 3 with value: 0.6722302429226037.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:14,246] Trial 5 finished with value: 0.6587847592743706 and parameters: {'num_leaves': 85, 'min_data_in_leaf': 88, 'min_sum_hessian_in_leaf': 0.004788147156768277, 'feature_fraction': 0.9720800091019398, 'bagging_fraction': 0.7509183379421682, 'lambda_l1': 3.1319282717196035, 'lambda_l2': 0.029005047452739414}. Best is trial 3 with value: 0.6722302429226037.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:14,458] Trial 6 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 87, 'min_data_in_leaf': 86, 'min_sum_hessian_in_leaf': 0.003971252247766701, 'feature_fraction': 0.6252276826982534, 'bagging_fraction': 0.7415171321313522, 'lambda_l1': 87.54657140659076, 'lambda_l2': 1.1965765212602313}. Best is trial 3 with value: 0.6722302429226037.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:15,261] Trial 7 finished with value: 0.6992530286862093 and parameters: {'num_leaves': 160, 'min_data_in_leaf': 28, 'min_sum_hessian_in_leaf': 0.0030131614432849746, 'feature_fraction': 0.8015300642054637, 'bagging_fraction': 0.7725340032332324, 'lambda_l1': 0.23499322154972468, 'lambda_l2': 0.1646202117975735}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:15,779] Trial 8 finished with value: 0.6823363254033017 and parameters: {'num_leaves': 111, 'min_data_in_leaf': 138, 'min_sum_hessian_in_leaf': 0.00423029374725911, 'feature_fraction': 0.7552111687390055, 'bagging_fraction': 0.8346568914811361, 'lambda_l1': 2.206714812711709, 'lambda_l2': 3.1594683442464033}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:16,054] Trial 9 finished with value: 0.6362751867428285 and parameters: {'num_leaves': 175, 'min_data_in_leaf': 170, 'min_sum_hessian_in_leaf': 1.7765808030254076e-05, 'feature_fraction': 0.8818414207216692, 'bagging_fraction': 0.6218331872684371, 'lambda_l1': 0.05982625838323253, 'lambda_l2': 1.9490717640641542}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:16,599] Trial 10 finished with value: 0.673435440336451 and parameters: {'num_leaves': 32, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 0.0009194171614722974, 'feature_fraction': 0.5040305717020102, 'bagging_fraction': 0.9940542446575642, 'lambda_l1': 0.010612397212799423, 'lambda_l2': 0.1661409929489422}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:16,842] Trial 11 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 141, 'min_data_in_leaf': 198, 'min_sum_hessian_in_leaf': 0.009951069387483545, 'feature_fraction': 0.7991399603154743, 'bagging_fraction': 0.8761275059380933, 'lambda_l1': 8.895512707730266, 'lambda_l2': 11.692356850069807}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=8.895512707730266, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730266\n[LightGBM] [Warning] bagging_fraction is set=0.8761275059380933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380933\n[LightGBM] [Warning] lambda_l2 is set=11.692356850069807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069807\n[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=8.895512707730266, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730266\n[LightGBM] [Warning] bagging_fraction is set=0.8761275059380933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380933\n[LightGBM] [Warning] lambda_l2 is set=11.692356850069807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069807\n[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=8.895512707730266, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730266\n[LightGBM] [Warning] bagging_fraction is set=0.8761275059380933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380933\n[LightGBM] [Warning] lambda_l2 is set=11.692356850069807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069807\n[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=8.895512707730266, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730266\n[LightGBM] [Warning] bagging_fraction is set=0.8761275059380933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380933\n[LightGBM] [Warning] lambda_l2 is set=11.692356850069807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069807\n[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=8.895512707730266, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730266\n[LightGBM] [Warning] bagging_fraction is set=0.8761275059380933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380933\n[LightGBM] [Warning] lambda_l2 is set=11.692356850069807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069807\n[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:17,821] Trial 12 finished with value: 0.6802083987194777 and parameters: {'num_leaves': 255, 'min_data_in_leaf': 18, 'min_sum_hessian_in_leaf': 0.001634914743632515, 'feature_fraction': 0.8476730378212194, 'bagging_fraction': 0.5595408581248553, 'lambda_l1': 0.09349295720311095, 'lambda_l2': 0.2669531355707319}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n[LightGBM] [Warning] lambda_l2 is set=16.04887249986447, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.04887249986447\n[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n[LightGBM] [Warning] lambda_l2 is set=16.04887249986447, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.04887249986447\n[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:18,201] Trial 13 finished with value: 0.6712196346745339 and parameters: {'num_leaves': 140, 'min_data_in_leaf': 43, 'min_sum_hessian_in_leaf': 0.0021756690901938718, 'feature_fraction': 0.9479314162009256, 'bagging_fraction': 0.9474999290561824, 'lambda_l1': 15.027486795162927, 'lambda_l2': 16.04887249986447}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n[LightGBM] [Warning] lambda_l2 is set=16.04887249986447, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.04887249986447\n[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n[LightGBM] [Warning] lambda_l2 is set=16.04887249986447, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.04887249986447\n[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n[LightGBM] [Warning] lambda_l2 is set=16.04887249986447, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.04887249986447\n[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.10302449045855197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855197\n[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n[LightGBM] [Warning] lambda_l2 is set=7.1467516807077525, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.1467516807077525\n[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.10302449045855197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855197\n[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n[LightGBM] [Warning] lambda_l2 is set=7.1467516807077525, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.1467516807077525\n[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.10302449045855197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855197\n[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n[LightGBM] [Warning] lambda_l2 is set=7.1467516807077525, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.1467516807077525\n[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:18,702] Trial 14 finished with value: 0.6846400100433118 and parameters: {'num_leaves': 31, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 0.0002511161117887837, 'feature_fraction': 0.7214624501496751, 'bagging_fraction': 0.8148189817022143, 'lambda_l1': 0.10302449045855197, 'lambda_l2': 7.1467516807077525}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.10302449045855197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855197\n[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n[LightGBM] [Warning] lambda_l2 is set=7.1467516807077525, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.1467516807077525\n[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.10302449045855197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855197\n[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n[LightGBM] [Warning] lambda_l2 is set=7.1467516807077525, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.1467516807077525\n[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.026008451540619953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619953\n[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n[LightGBM] [Warning] lambda_l2 is set=12.21210843043782, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.21210843043782\n[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.026008451540619953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619953\n[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n[LightGBM] [Warning] lambda_l2 is set=12.21210843043782, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.21210843043782\n[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.026008451540619953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619953\n[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n[LightGBM] [Warning] lambda_l2 is set=12.21210843043782, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.21210843043782\n[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:19,210] Trial 15 finished with value: 0.6745904211913878 and parameters: {'num_leaves': 9, 'min_data_in_leaf': 46, 'min_sum_hessian_in_leaf': 0.00023305225408823253, 'feature_fraction': 0.690460596426745, 'bagging_fraction': 0.8032054077767327, 'lambda_l1': 0.026008451540619953, 'lambda_l2': 12.21210843043782}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.026008451540619953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619953\n[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n[LightGBM] [Warning] lambda_l2 is set=12.21210843043782, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.21210843043782\n[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.026008451540619953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619953\n[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n[LightGBM] [Warning] lambda_l2 is set=12.21210843043782, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.21210843043782\n[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.14515159340667338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667338\n[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n[LightGBM] [Warning] lambda_l2 is set=34.66806840700916, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.66806840700916\n[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00014054556930505904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00014054556930505904\n[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.14515159340667338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667338\n[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n[LightGBM] [Warning] lambda_l2 is set=34.66806840700916, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.66806840700916\n[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00014054556930505904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00014054556930505904\n[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.14515159340667338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667338\n[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n[LightGBM] [Warning] lambda_l2 is set=34.66806840700916, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.66806840700916\n[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00014054556930505904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00014054556930505904\n[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:19,677] Trial 16 finished with value: 0.6778858828698764 and parameters: {'num_leaves': 41, 'min_data_in_leaf': 65, 'min_sum_hessian_in_leaf': 0.00014054556930505904, 'feature_fraction': 0.816763159679514, 'bagging_fraction': 0.6677912738306708, 'lambda_l1': 0.14515159340667338, 'lambda_l2': 34.66806840700916}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.14515159340667338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667338\n[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n[LightGBM] [Warning] lambda_l2 is set=34.66806840700916, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.66806840700916\n[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00014054556930505904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00014054556930505904\n[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.14515159340667338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667338\n[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n[LightGBM] [Warning] lambda_l2 is set=34.66806840700916, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.66806840700916\n[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00014054556930505904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00014054556930505904\n[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n[LightGBM] [Warning] bagging_fraction is set=0.5002172961009613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009613\n[LightGBM] [Warning] lambda_l2 is set=0.04837506886369723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04837506886369723\n[LightGBM] [Warning] feature_fraction is set=0.6231218216909848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909848\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n[LightGBM] [Warning] bagging_fraction is set=0.5002172961009613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009613\n[LightGBM] [Warning] lambda_l2 is set=0.04837506886369723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04837506886369723\n[LightGBM] [Warning] feature_fraction is set=0.6231218216909848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909848\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n[LightGBM] [Warning] bagging_fraction is set=0.5002172961009613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009613\n[LightGBM] [Warning] lambda_l2 is set=0.04837506886369723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04837506886369723\n[LightGBM] [Warning] feature_fraction is set=0.6231218216909848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909848\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n[LightGBM] [Warning] bagging_fraction is set=0.5002172961009613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009613\n[LightGBM] [Warning] lambda_l2 is set=0.04837506886369723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04837506886369723\n[LightGBM] [Warning] feature_fraction is set=0.6231218216909848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909848\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n[LightGBM] [Warning] bagging_fraction is set=0.5002172961009613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009613\n[LightGBM] [Warning] lambda_l2 is set=0.04837506886369723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04837506886369723\n[LightGBM] [Warning] feature_fraction is set=0.6231218216909848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909848\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:20,253] Trial 17 finished with value: 0.6801393509509761 and parameters: {'num_leaves': 48, 'min_data_in_leaf': 28, 'min_sum_hessian_in_leaf': 0.00041942600526778174, 'feature_fraction': 0.6231218216909848, 'bagging_fraction': 0.5002172961009613, 'lambda_l1': 0.03426707576896973, 'lambda_l2': 0.04837506886369723}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.18409793634935437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18409793634935437\n[LightGBM] [Warning] bagging_fraction is set=0.9432358972978486, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978486\n[LightGBM] [Warning] lambda_l2 is set=0.42463135597338925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338925\n[LightGBM] [Warning] feature_fraction is set=0.9236171148088437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088437\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.90220458942919e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.90220458942919e-05\n[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.18409793634935437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18409793634935437\n[LightGBM] [Warning] bagging_fraction is set=0.9432358972978486, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978486\n[LightGBM] [Warning] lambda_l2 is set=0.42463135597338925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338925\n[LightGBM] [Warning] feature_fraction is set=0.9236171148088437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088437\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.90220458942919e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.90220458942919e-05\n[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.18409793634935437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18409793634935437\n[LightGBM] [Warning] bagging_fraction is set=0.9432358972978486, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978486\n[LightGBM] [Warning] lambda_l2 is set=0.42463135597338925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338925\n[LightGBM] [Warning] feature_fraction is set=0.9236171148088437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088437\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.90220458942919e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.90220458942919e-05\n[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.18409793634935437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18409793634935437\n[LightGBM] [Warning] bagging_fraction is set=0.9432358972978486, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978486\n[LightGBM] [Warning] lambda_l2 is set=0.42463135597338925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338925\n[LightGBM] [Warning] feature_fraction is set=0.9236171148088437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088437\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.90220458942919e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.90220458942919e-05\n[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:20,934] Trial 18 finished with value: 0.6790848032138597 and parameters: {'num_leaves': 218, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 7.90220458942919e-05, 'feature_fraction': 0.9236171148088437, 'bagging_fraction': 0.9432358972978486, 'lambda_l1': 0.18409793634935437, 'lambda_l2': 0.42463135597338925}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.18409793634935437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18409793634935437\n[LightGBM] [Warning] bagging_fraction is set=0.9432358972978486, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978486\n[LightGBM] [Warning] lambda_l2 is set=0.42463135597338925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338925\n[LightGBM] [Warning] feature_fraction is set=0.9236171148088437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088437\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.90220458942919e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.90220458942919e-05\n[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.010045321756357375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357375\n[LightGBM] [Warning] bagging_fraction is set=0.805029885015916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.805029885015916\n[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n[LightGBM] [Warning] feature_fraction is set=0.7302924887036465, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036465\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.010045321756357375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357375\n[LightGBM] [Warning] bagging_fraction is set=0.805029885015916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.805029885015916\n[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n[LightGBM] [Warning] feature_fraction is set=0.7302924887036465, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036465\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.010045321756357375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357375\n[LightGBM] [Warning] bagging_fraction is set=0.805029885015916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.805029885015916\n[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n[LightGBM] [Warning] feature_fraction is set=0.7302924887036465, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036465\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.010045321756357375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357375\n[LightGBM] [Warning] bagging_fraction is set=0.805029885015916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.805029885015916\n[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n[LightGBM] [Warning] feature_fraction is set=0.7302924887036465, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036465\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:21,307] Trial 19 finished with value: 0.6622308706295901 and parameters: {'num_leaves': 160, 'min_data_in_leaf': 113, 'min_sum_hessian_in_leaf': 0.0004165592806968668, 'feature_fraction': 0.7302924887036465, 'bagging_fraction': 0.805029885015916, 'lambda_l1': 0.010045321756357375, 'lambda_l2': 0.0995890378098838}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.010045321756357375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357375\n[LightGBM] [Warning] bagging_fraction is set=0.805029885015916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.805029885015916\n[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n[LightGBM] [Warning] feature_fraction is set=0.7302924887036465, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036465\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.3216819410872765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872765\n[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n[LightGBM] [Warning] lambda_l2 is set=0.9453451423419853, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9453451423419853\n[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.3216819410872765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872765\n[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n[LightGBM] [Warning] lambda_l2 is set=0.9453451423419853, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9453451423419853\n[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.3216819410872765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872765\n[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n[LightGBM] [Warning] lambda_l2 is set=0.9453451423419853, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9453451423419853\n[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.3216819410872765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872765\n[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n[LightGBM] [Warning] lambda_l2 is set=0.9453451423419853, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9453451423419853\n[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:21,934] Trial 20 finished with value: 0.6745904211913879 and parameters: {'num_leaves': 209, 'min_data_in_leaf': 35, 'min_sum_hessian_in_leaf': 0.0013845801360137025, 'feature_fraction': 0.5306298908707103, 'bagging_fraction': 0.6900582768491921, 'lambda_l1': 0.3216819410872765, 'lambda_l2': 0.9453451423419853}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.3216819410872765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872765\n[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n[LightGBM] [Warning] lambda_l2 is set=0.9453451423419853, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9453451423419853\n[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=3.445630241563508, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445630241563508\n[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n[LightGBM] [Warning] lambda_l2 is set=4.156916351584709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584709\n[LightGBM] [Warning] feature_fraction is set=0.7668244440376193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376193\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008748025832898368, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.008748025832898368\n[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=3.445630241563508, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445630241563508\n[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n[LightGBM] [Warning] lambda_l2 is set=4.156916351584709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584709\n[LightGBM] [Warning] feature_fraction is set=0.7668244440376193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376193\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008748025832898368, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.008748025832898368\n[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=3.445630241563508, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445630241563508\n[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n[LightGBM] [Warning] lambda_l2 is set=4.156916351584709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584709\n[LightGBM] [Warning] feature_fraction is set=0.7668244440376193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376193\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008748025832898368, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.008748025832898368\n[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:22,552] Trial 21 finished with value: 0.6667252526520621 and parameters: {'num_leaves': 106, 'min_data_in_leaf': 73, 'min_sum_hessian_in_leaf': 0.008748025832898368, 'feature_fraction': 0.7668244440376193, 'bagging_fraction': 0.8140984986812078, 'lambda_l1': 3.445630241563508, 'lambda_l2': 4.156916351584709}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=3.445630241563508, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445630241563508\n[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n[LightGBM] [Warning] lambda_l2 is set=4.156916351584709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584709\n[LightGBM] [Warning] feature_fraction is set=0.7668244440376193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376193\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008748025832898368, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.008748025832898368\n[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=3.445630241563508, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445630241563508\n[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n[LightGBM] [Warning] lambda_l2 is set=4.156916351584709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584709\n[LightGBM] [Warning] feature_fraction is set=0.7668244440376193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376193\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008748025832898368, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.008748025832898368\n[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=2.1127374904866487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1127374904866487\n[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n[LightGBM] [Warning] lambda_l2 is set=4.554403222246632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246632\n[LightGBM] [Warning] feature_fraction is set=0.7482688842343571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343571\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=2.1127374904866487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1127374904866487\n[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n[LightGBM] [Warning] lambda_l2 is set=4.554403222246632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246632\n[LightGBM] [Warning] feature_fraction is set=0.7482688842343571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343571\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=2.1127374904866487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1127374904866487\n[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n[LightGBM] [Warning] lambda_l2 is set=4.554403222246632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246632\n[LightGBM] [Warning] feature_fraction is set=0.7482688842343571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343571\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=2.1127374904866487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1127374904866487\n[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n[LightGBM] [Warning] lambda_l2 is set=4.554403222246632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246632\n[LightGBM] [Warning] feature_fraction is set=0.7482688842343571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343571\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:22,965] Trial 22 finished with value: 0.6644152909421882 and parameters: {'num_leaves': 62, 'min_data_in_leaf': 129, 'min_sum_hessian_in_leaf': 0.004061668550970804, 'feature_fraction': 0.7482688842343571, 'bagging_fraction': 0.8886750178544316, 'lambda_l1': 2.1127374904866487, 'lambda_l2': 4.554403222246632}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=2.1127374904866487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1127374904866487\n[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n[LightGBM] [Warning] lambda_l2 is set=4.554403222246632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246632\n[LightGBM] [Warning] feature_fraction is set=0.7482688842343571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343571\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=8.59982035475244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.59982035475244\n[LightGBM] [Warning] bagging_fraction is set=0.8221198194153576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153576\n[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n[LightGBM] [Warning] feature_fraction is set=0.6773917561139398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139398\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0026312807570427793, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0026312807570427793\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:23,263] Trial 23 finished with value: 0.6453141673466826 and parameters: {'num_leaves': 111, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 0.0026312807570427793, 'feature_fraction': 0.6773917561139398, 'bagging_fraction': 0.8221198194153576, 'lambda_l1': 8.59982035475244, 'lambda_l2': 0.7542908028826634}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=8.59982035475244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.59982035475244\n[LightGBM] [Warning] bagging_fraction is set=0.8221198194153576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153576\n[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n[LightGBM] [Warning] feature_fraction is set=0.6773917561139398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139398\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0026312807570427793, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0026312807570427793\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=8.59982035475244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.59982035475244\n[LightGBM] [Warning] bagging_fraction is set=0.8221198194153576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153576\n[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n[LightGBM] [Warning] feature_fraction is set=0.6773917561139398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139398\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0026312807570427793, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0026312807570427793\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=8.59982035475244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.59982035475244\n[LightGBM] [Warning] bagging_fraction is set=0.8221198194153576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153576\n[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n[LightGBM] [Warning] feature_fraction is set=0.6773917561139398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139398\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0026312807570427793, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0026312807570427793\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=8.59982035475244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.59982035475244\n[LightGBM] [Warning] bagging_fraction is set=0.8221198194153576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153576\n[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n[LightGBM] [Warning] feature_fraction is set=0.6773917561139398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139398\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0026312807570427793, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0026312807570427793\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.054062737213373784, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373784\n[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n[LightGBM] [Warning] lambda_l2 is set=7.254429610183551, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183551\n[LightGBM] [Warning] feature_fraction is set=0.8193477007279062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279062\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101101, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101101\n[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.054062737213373784, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373784\n[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n[LightGBM] [Warning] lambda_l2 is set=7.254429610183551, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183551\n[LightGBM] [Warning] feature_fraction is set=0.8193477007279062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279062\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101101, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101101\n[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:23,716] Trial 24 finished with value: 0.6823488795430293 and parameters: {'num_leaves': 9, 'min_data_in_leaf': 164, 'min_sum_hessian_in_leaf': 0.0007958826711101101, 'feature_fraction': 0.8193477007279062, 'bagging_fraction': 0.9137850613244668, 'lambda_l1': 0.054062737213373784, 'lambda_l2': 7.254429610183551}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.054062737213373784, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373784\n[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n[LightGBM] [Warning] lambda_l2 is set=7.254429610183551, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183551\n[LightGBM] [Warning] feature_fraction is set=0.8193477007279062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279062\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101101, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101101\n[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.054062737213373784, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373784\n[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n[LightGBM] [Warning] lambda_l2 is set=7.254429610183551, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183551\n[LightGBM] [Warning] feature_fraction is set=0.8193477007279062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279062\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101101, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101101\n[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.054062737213373784, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373784\n[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n[LightGBM] [Warning] lambda_l2 is set=7.254429610183551, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183551\n[LightGBM] [Warning] feature_fraction is set=0.8193477007279062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279062\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101101, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101101\n[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n[LightGBM] [Warning] feature_fraction is set=0.897993229060577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.897993229060577\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542904\n[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n[LightGBM] [Warning] feature_fraction is set=0.897993229060577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.897993229060577\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542904\n[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n[LightGBM] [Warning] feature_fraction is set=0.897993229060577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.897993229060577\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542904\n[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n[LightGBM] [Warning] feature_fraction is set=0.897993229060577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.897993229060577\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542904\n[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:24,163] Trial 25 finished with value: 0.6599836796183542 and parameters: {'num_leaves': 21, 'min_data_in_leaf': 176, 'min_sum_hessian_in_leaf': 0.0007220208410542904, 'feature_fraction': 0.897993229060577, 'bagging_fraction': 0.9096697647298414, 'lambda_l1': 0.04052688745892243, 'lambda_l2': 33.56741330161014}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n[LightGBM] [Warning] feature_fraction is set=0.897993229060577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.897993229060577\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542904\n[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.07242256998354961, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354961\n[LightGBM] [Warning] bagging_fraction is set=0.777469997490065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777469997490065\n[LightGBM] [Warning] lambda_l2 is set=6.818961945625027, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625027\n[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.07242256998354961, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354961\n[LightGBM] [Warning] bagging_fraction is set=0.777469997490065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777469997490065\n[LightGBM] [Warning] lambda_l2 is set=6.818961945625027, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625027\n[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.07242256998354961, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354961\n[LightGBM] [Warning] bagging_fraction is set=0.777469997490065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777469997490065\n[LightGBM] [Warning] lambda_l2 is set=6.818961945625027, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625027\n[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.07242256998354961, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354961\n[LightGBM] [Warning] bagging_fraction is set=0.777469997490065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777469997490065\n[LightGBM] [Warning] lambda_l2 is set=6.818961945625027, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625027\n[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:25,080] Trial 26 finished with value: 0.6757140166970059 and parameters: {'num_leaves': 63, 'min_data_in_leaf': 49, 'min_sum_hessian_in_leaf': 0.00019985545118893227, 'feature_fraction': 0.8168240033302105, 'bagging_fraction': 0.777469997490065, 'lambda_l1': 0.07242256998354961, 'lambda_l2': 6.818961945625027}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.07242256998354961, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354961\n[LightGBM] [Warning] bagging_fraction is set=0.777469997490065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777469997490065\n[LightGBM] [Warning] lambda_l2 is set=6.818961945625027, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625027\n[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n[LightGBM] [Warning] lambda_l2 is set=1.9898087013583565, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583565\n[LightGBM] [Warning] feature_fraction is set=0.832859028154117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.832859028154117\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549305, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549305\n[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n[LightGBM] [Warning] lambda_l2 is set=1.9898087013583565, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583565\n[LightGBM] [Warning] feature_fraction is set=0.832859028154117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.832859028154117\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549305, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549305\n[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n[LightGBM] [Warning] lambda_l2 is set=1.9898087013583565, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583565\n[LightGBM] [Warning] feature_fraction is set=0.832859028154117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.832859028154117\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549305, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549305\n[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:25,573] Trial 27 finished with value: 0.6700207143305505 and parameters: {'num_leaves': 9, 'min_data_in_leaf': 110, 'min_sum_hessian_in_leaf': 0.0011015177430549305, 'feature_fraction': 0.832859028154117, 'bagging_fraction': 0.9245894599408239, 'lambda_l1': 0.13213697905758195, 'lambda_l2': 1.9898087013583565}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n[LightGBM] [Warning] lambda_l2 is set=1.9898087013583565, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583565\n[LightGBM] [Warning] feature_fraction is set=0.832859028154117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.832859028154117\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549305, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549305\n[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n[LightGBM] [Warning] lambda_l2 is set=1.9898087013583565, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583565\n[LightGBM] [Warning] feature_fraction is set=0.832859028154117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.832859028154117\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549305, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549305\n[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:25,817] Trial 28 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 54, 'min_data_in_leaf': 169, 'min_sum_hessian_in_leaf': 0.0004463850369701868, 'feature_fraction': 0.7818076921940365, 'bagging_fraction': 0.7239926057056618, 'lambda_l1': 0.26894380562875153, 'lambda_l2': 82.43363076639685}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.26894380562875153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875153\n[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n[LightGBM] [Warning] feature_fraction is set=0.7818076921940365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940365\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004463850369701868, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004463850369701868\n[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.26894380562875153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875153\n[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n[LightGBM] [Warning] feature_fraction is set=0.7818076921940365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940365\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004463850369701868, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004463850369701868\n[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.26894380562875153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875153\n[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n[LightGBM] [Warning] feature_fraction is set=0.7818076921940365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940365\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004463850369701868, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004463850369701868\n[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.26894380562875153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875153\n[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n[LightGBM] [Warning] feature_fraction is set=0.7818076921940365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940365\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004463850369701868, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004463850369701868\n[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.26894380562875153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875153\n[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n[LightGBM] [Warning] feature_fraction is set=0.7818076921940365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940365\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004463850369701868, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004463850369701868\n[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.02276315503480073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02276315503480073\n[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.02276315503480073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02276315503480073\n[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.02276315503480073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02276315503480073\n[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-12-19 08:40:26,138] Trial 29 finished with value: 0.6587470968551881 and parameters: {'num_leaves': 161, 'min_data_in_leaf': 196, 'min_sum_hessian_in_leaf': 8.505644215173895e-05, 'feature_fraction': 0.7116385045852216, 'bagging_fraction': 0.9850169158486759, 'lambda_l1': 0.02276315503480073, 'lambda_l2': 32.318206202200265}. Best is trial 7 with value: 0.6992530286862093.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] lambda_l1 is set=0.02276315503480073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02276315503480073\n[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n[LightGBM] [Warning] lambda_l1 is set=0.02276315503480073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02276315503480073\n[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n","output_type":"stream"}],"execution_count":6},{"id":"0db0f7da","cell_type":"markdown","source":"#### スクリプト6-4: 探索結果の確認","metadata":{"papermill":{"duration":0.049025,"end_time":"2024-02-14T12:57:16.272144","exception":false,"start_time":"2024-02-14T12:57:16.223119","status":"completed"},"tags":[]}},{"id":"e48b082a","cell_type":"code","source":"trial = study.best_trial\nprint(\"acc(best)={:.4f}\".format(trial.value))\ndisplay(trial.params)","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.143481Z","iopub.execute_input":"2024-12-19T08:40:26.143756Z","iopub.status.idle":"2024-12-19T08:40:26.152760Z","shell.execute_reply.started":"2024-12-19T08:40:26.143732Z","shell.execute_reply":"2024-12-19T08:40:26.151372Z"},"papermill":{"duration":0.063234,"end_time":"2024-02-14T12:57:16.383795","exception":false,"start_time":"2024-02-14T12:57:16.320561","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"acc(best)=0.6993\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"{'num_leaves': 160,\n 'min_data_in_leaf': 28,\n 'min_sum_hessian_in_leaf': 0.0030131614432849746,\n 'feature_fraction': 0.8015300642054637,\n 'bagging_fraction': 0.7725340032332324,\n 'lambda_l1': 0.23499322154972468,\n 'lambda_l2': 0.1646202117975735}"},"metadata":{}}],"execution_count":7},{"id":"912f3030","cell_type":"markdown","source":"#### スクリプト6-5: ベストなハイパーパラメータの取得","metadata":{"papermill":{"duration":0.049835,"end_time":"2024-02-14T12:57:16.484088","exception":false,"start_time":"2024-02-14T12:57:16.434253","status":"completed"},"tags":[]}},{"id":"22a53ded","cell_type":"code","source":"params_best = trial.params\nparams_best.update(params_base)\ndisplay(params_best)","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.155379Z","iopub.execute_input":"2024-12-19T08:40:26.155726Z","iopub.status.idle":"2024-12-19T08:40:26.188464Z","shell.execute_reply.started":"2024-12-19T08:40:26.155693Z","shell.execute_reply":"2024-12-19T08:40:26.187119Z"},"papermill":{"duration":0.062092,"end_time":"2024-02-14T12:57:16.595352","exception":false,"start_time":"2024-02-14T12:57:16.533260","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"{'num_leaves': 160,\n 'min_data_in_leaf': 28,\n 'min_sum_hessian_in_leaf': 0.0030131614432849746,\n 'feature_fraction': 0.8015300642054637,\n 'bagging_fraction': 0.7725340032332324,\n 'lambda_l1': 0.23499322154972468,\n 'lambda_l2': 0.1646202117975735,\n 'boosting_type': 'gbdt',\n 'objective': 'binary',\n 'metric': 'auc',\n 'learning_rate': 0.02,\n 'n_estimators': 100000,\n 'bagging_freq': 1,\n 'seed': 123}"},"metadata":{}}],"execution_count":8},{"id":"1bcdd63f","cell_type":"markdown","source":"# 6.2 LightGBM以外のモデル利用\n## 6.2.1 scikit-learnの各種モデル","metadata":{"papermill":{"duration":0.049184,"end_time":"2024-02-14T12:57:16.695388","exception":false,"start_time":"2024-02-14T12:57:16.646204","status":"completed"},"tags":[]}},{"id":"b0a57483","cell_type":"markdown","source":"### Titanicデータを用いた例：ロジスティック回帰\n#### スクリプト6-6: ファイル読み込みとデータセット作成","metadata":{"papermill":{"duration":0.048952,"end_time":"2024-02-14T12:57:16.794003","exception":false,"start_time":"2024-02-14T12:57:16.745051","status":"completed"},"tags":[]}},{"id":"aa3f42ac","cell_type":"code","source":"# ファイル読み込み\ndf_train = pd.read_csv(\"../input/titanic/train.csv\")\n\n# データセット作成\nx_train = df_train[[\"Pclass\", \"Age\", \"Embarked\"]]\ny_train = df_train[[\"Survived\"]]","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.190232Z","iopub.execute_input":"2024-12-19T08:40:26.190634Z","iopub.status.idle":"2024-12-19T08:40:26.218644Z","shell.execute_reply.started":"2024-12-19T08:40:26.190598Z","shell.execute_reply":"2024-12-19T08:40:26.217447Z"},"papermill":{"duration":0.067453,"end_time":"2024-02-14T12:57:16.911385","exception":false,"start_time":"2024-02-14T12:57:16.843932","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"id":"6683f2bb","cell_type":"code","source":"# 欠損値の確認\nx_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.219656Z","iopub.execute_input":"2024-12-19T08:40:26.220074Z","iopub.status.idle":"2024-12-19T08:40:26.229247Z","shell.execute_reply.started":"2024-12-19T08:40:26.220016Z","shell.execute_reply":"2024-12-19T08:40:26.228044Z"},"papermill":{"duration":0.06567,"end_time":"2024-02-14T12:57:17.026674","exception":false,"start_time":"2024-02-14T12:57:16.961004","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Pclass        0\nAge         177\nEmbarked      2\ndtype: int64"},"metadata":{}}],"execution_count":10},{"id":"b114b4ae","cell_type":"markdown","source":"#### スクリプト6-7: 欠損値の補間","metadata":{"papermill":{"duration":0.050855,"end_time":"2024-02-14T12:57:17.131554","exception":false,"start_time":"2024-02-14T12:57:17.080699","status":"completed"},"tags":[]}},{"id":"290a4706","cell_type":"code","source":"# 欠損値補間：数値データ\nx_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n\n# 欠損値補間：カテゴリ変数\nx_train[\"Embarked\"] = x_train[\"Embarked\"].fillna(x_train[\"Embarked\"].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.230362Z","iopub.execute_input":"2024-12-19T08:40:26.230832Z","iopub.status.idle":"2024-12-19T08:40:26.250459Z","shell.execute_reply.started":"2024-12-19T08:40:26.230789Z","shell.execute_reply":"2024-12-19T08:40:26.249007Z"},"papermill":{"duration":0.064259,"end_time":"2024-02-14T12:57:17.245390","exception":false,"start_time":"2024-02-14T12:57:17.181131","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"id":"ea4f6c1a","cell_type":"markdown","source":"#### スクリプト6-8: カテゴリ変数の数値化（one-hot-encoding）","metadata":{"papermill":{"duration":0.052395,"end_time":"2024-02-14T12:57:17.349477","exception":false,"start_time":"2024-02-14T12:57:17.297082","status":"completed"},"tags":[]}},{"id":"e77d5dfc","cell_type":"code","source":"ohe = OneHotEncoder()\nohe.fit(x_train[[\"Embarked\"]])\ndf_embarked = pd.DataFrame(\n    ohe.transform(x_train[[\"Embarked\"]]).toarray(), \n    columns=[\"Embarked_{}\".format(col) for col in ohe.categories_[0]])\n\nx_train = pd.concat([x_train, df_embarked], axis=1)\nx_train = x_train.drop(columns=[\"Embarked\"])","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.251670Z","iopub.execute_input":"2024-12-19T08:40:26.252034Z","iopub.status.idle":"2024-12-19T08:40:26.281364Z","shell.execute_reply.started":"2024-12-19T08:40:26.252002Z","shell.execute_reply":"2024-12-19T08:40:26.280265Z"},"papermill":{"duration":0.069603,"end_time":"2024-02-14T12:57:17.469883","exception":false,"start_time":"2024-02-14T12:57:17.400280","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":12},{"id":"11bca5b9","cell_type":"markdown","source":"#### スクリプト6-9: 数値データの正規化","metadata":{"papermill":{"duration":0.04881,"end_time":"2024-02-14T12:57:17.568228","exception":false,"start_time":"2024-02-14T12:57:17.519418","status":"completed"},"tags":[]}},{"id":"842a2bf0","cell_type":"code","source":"x_train[\"Pclass\"] = (x_train[\"Pclass\"] -x_train[\"Pclass\"].min()) / (x_train[\"Pclass\"].max() - x_train[\"Pclass\"].min()) \nx_train[\"Age\"] = (x_train[\"Age\"] -x_train[\"Age\"].min()) / (x_train[\"Age\"].max() - x_train[\"Age\"].min()) ","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.282333Z","iopub.execute_input":"2024-12-19T08:40:26.282704Z","iopub.status.idle":"2024-12-19T08:40:26.296113Z","shell.execute_reply.started":"2024-12-19T08:40:26.282673Z","shell.execute_reply":"2024-12-19T08:40:26.295007Z"},"papermill":{"duration":0.062075,"end_time":"2024-02-14T12:57:17.680202","exception":false,"start_time":"2024-02-14T12:57:17.618127","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"id":"cdb5486a","cell_type":"markdown","source":"#### スクリプト6-10: 学習データと検証データの分割（ホールドアウト検証）","metadata":{"papermill":{"duration":0.05211,"end_time":"2024-02-14T12:57:17.782862","exception":false,"start_time":"2024-02-14T12:57:17.730752","status":"completed"},"tags":[]}},{"id":"f05cf1d0","cell_type":"code","source":"x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=123)\nprint(x_tr.shape, x_va.shape, y_tr.shape, y_va.shape)","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.297247Z","iopub.execute_input":"2024-12-19T08:40:26.297553Z","iopub.status.idle":"2024-12-19T08:40:26.325726Z","shell.execute_reply.started":"2024-12-19T08:40:26.297519Z","shell.execute_reply":"2024-12-19T08:40:26.324735Z"},"papermill":{"duration":0.070415,"end_time":"2024-02-14T12:57:17.903445","exception":false,"start_time":"2024-02-14T12:57:17.833030","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"(712, 5) (179, 5) (712, 1) (179, 1)\n","output_type":"stream"}],"execution_count":14},{"id":"54b654b9","cell_type":"markdown","source":"#### スクリプト6-11: LogisticRegression","metadata":{"papermill":{"duration":0.048979,"end_time":"2024-02-14T12:57:18.002107","exception":false,"start_time":"2024-02-14T12:57:17.953128","status":"completed"},"tags":[]}},{"id":"22282adb","cell_type":"code","source":"# モデル定義\nfrom sklearn.linear_model import LogisticRegression\nmodel_logis = LogisticRegression()\n\n# 学習\nmodel_logis.fit(x_tr, y_tr)\n\n# 予測\ny_va_pred = model_logis.predict(x_va)\nprint(\"accuracy:{:.4f}\".format(accuracy_score(y_va, y_va_pred)))\nprint(y_va_pred[:5])","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.326791Z","iopub.execute_input":"2024-12-19T08:40:26.327096Z","iopub.status.idle":"2024-12-19T08:40:26.381946Z","shell.execute_reply.started":"2024-12-19T08:40:26.327068Z","shell.execute_reply":"2024-12-19T08:40:26.380910Z"},"papermill":{"duration":0.102963,"end_time":"2024-02-14T12:57:18.154908","exception":false,"start_time":"2024-02-14T12:57:18.051945","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"accuracy:0.7263\n[0 1 0 1 0]\n","output_type":"stream"}],"execution_count":15},{"id":"2cbd2514","cell_type":"markdown","source":"#### スクリプト6-12: 確率値の取得","metadata":{"papermill":{"duration":0.049722,"end_time":"2024-02-14T12:57:18.255685","exception":false,"start_time":"2024-02-14T12:57:18.205963","status":"completed"},"tags":[]}},{"id":"96f8d15d","cell_type":"code","source":"y_va_pred_proba = model_logis.predict_proba(x_va)\nprint(y_va_pred_proba[:5, :])","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.383099Z","iopub.execute_input":"2024-12-19T08:40:26.383428Z","iopub.status.idle":"2024-12-19T08:40:26.390808Z","shell.execute_reply.started":"2024-12-19T08:40:26.383401Z","shell.execute_reply":"2024-12-19T08:40:26.389282Z"},"papermill":{"duration":0.065287,"end_time":"2024-02-14T12:57:18.370193","exception":false,"start_time":"2024-02-14T12:57:18.304906","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"[[0.83621285 0.16378715]\n [0.23058311 0.76941689]\n [0.83244141 0.16755859]\n [0.32227072 0.67772928]\n [0.62569522 0.37430478]]\n","output_type":"stream"}],"execution_count":16},{"id":"2a3bf1ff","cell_type":"markdown","source":"### Titanicデータを用いた例：SVM\n#### スクリプト6-13: SVM","metadata":{"papermill":{"duration":0.049302,"end_time":"2024-02-14T12:57:18.469225","exception":false,"start_time":"2024-02-14T12:57:18.419923","status":"completed"},"tags":[]}},{"id":"7567d109","cell_type":"code","source":"# モデル定義\nfrom sklearn.svm import SVC\nmodel_svm = SVC(C=1.0, random_state=123, probability=True)\n\n# 学習\nmodel_svm.fit(x_tr, y_tr)\n\n# 予測\ny_va_pred = model_svm.predict(x_va)\nprint(\"accuracy:{:.4f}\".format(accuracy_score(y_va, y_va_pred)))\nprint(y_va_pred[:5])\n\n# 確率値の取得\ny_va_pred_proba = model_svm.predict_proba(x_va)\nprint(y_va_pred_proba[:5, :])","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.391731Z","iopub.execute_input":"2024-12-19T08:40:26.392064Z","iopub.status.idle":"2024-12-19T08:40:26.510413Z","shell.execute_reply.started":"2024-12-19T08:40:26.392032Z","shell.execute_reply":"2024-12-19T08:40:26.509306Z"},"papermill":{"duration":0.172296,"end_time":"2024-02-14T12:57:18.691544","exception":false,"start_time":"2024-02-14T12:57:18.519248","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"accuracy:0.7151\n[0 1 0 1 0]\n[[0.73985924 0.26014076]\n [0.28242534 0.71757466]\n [0.73986177 0.26013823]\n [0.26828214 0.73171786]\n [0.58950192 0.41049808]]\n","output_type":"stream"}],"execution_count":17},{"id":"f39133a1","cell_type":"markdown","source":"## 6.2.2 ニューラルネットワーク","metadata":{"papermill":{"duration":0.051277,"end_time":"2024-02-14T12:57:18.792432","exception":false,"start_time":"2024-02-14T12:57:18.741155","status":"completed"},"tags":[]}},{"id":"21e05a79","cell_type":"markdown","source":"\n### ニューラルネットワークの適用例：①全結合層のみのネットワークモデル\n#### スクリプト6-14: ライブラリのインポート","metadata":{"papermill":{"duration":0.05263,"end_time":"2024-02-14T12:57:18.895423","exception":false,"start_time":"2024-02-14T12:57:18.842793","status":"completed"},"tags":[]}},{"id":"4df7fc99","cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Embedding, Flatten, Concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\nfrom tensorflow.keras.optimizers import Adam, SGD","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:26.511623Z","iopub.execute_input":"2024-12-19T08:40:26.512031Z","iopub.status.idle":"2024-12-19T08:40:36.798432Z","shell.execute_reply.started":"2024-12-19T08:40:26.511992Z","shell.execute_reply":"2024-12-19T08:40:36.797439Z"},"papermill":{"duration":16.23305,"end_time":"2024-02-14T12:57:35.178405","exception":false,"start_time":"2024-02-14T12:57:18.945355","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":18},{"id":"0828dfa7","cell_type":"markdown","source":"#### スクリプト6-15: tensorflowの再現性のためのシード指定","metadata":{"papermill":{"duration":0.050145,"end_time":"2024-02-14T12:57:35.280265","exception":false,"start_time":"2024-02-14T12:57:35.230120","status":"completed"},"tags":[]}},{"id":"cbc77878","cell_type":"code","source":"def seed_everything(seed):\n    import random\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    # session_conf = tf.compat.v1.ConfigProto(\n    #     intra_op_parallelism_threads=1,\n    #     inter_op_parallelism_threads=1\n    # )\n    # sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n    # tf.compat.v1.keras.backend.set_session(sess)","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:36.799174Z","iopub.execute_input":"2024-12-19T08:40:36.799861Z","iopub.status.idle":"2024-12-19T08:40:36.805041Z","shell.execute_reply.started":"2024-12-19T08:40:36.799831Z","shell.execute_reply":"2024-12-19T08:40:36.803947Z"},"papermill":{"duration":0.076786,"end_time":"2024-02-14T12:57:35.406916","exception":false,"start_time":"2024-02-14T12:57:35.330130","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":19},{"id":"622e65ba","cell_type":"markdown","source":"#### スクリプト6-16: ファイルの読み込みとデータセット作成","metadata":{"papermill":{"duration":0.049653,"end_time":"2024-02-14T12:57:35.511642","exception":false,"start_time":"2024-02-14T12:57:35.461989","status":"completed"},"tags":[]}},{"id":"9511d898","cell_type":"code","source":"# ファイル読み込み\ndf_train = pd.read_csv(\"../input/titanic/train.csv\")\n\n# データセット作成\nx_train = df_train[[\"Pclass\", \"Age\", \"Embarked\"]]\ny_train = df_train[[\"Survived\"]]","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:36.806288Z","iopub.execute_input":"2024-12-19T08:40:36.806798Z","iopub.status.idle":"2024-12-19T08:40:36.833945Z","shell.execute_reply.started":"2024-12-19T08:40:36.806755Z","shell.execute_reply":"2024-12-19T08:40:36.832899Z"},"papermill":{"duration":0.065843,"end_time":"2024-02-14T12:57:35.626623","exception":false,"start_time":"2024-02-14T12:57:35.560780","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":20},{"id":"6a5bafc5","cell_type":"markdown","source":"#### スクリプト6-17: 数値データの前処理","metadata":{"papermill":{"duration":0.049392,"end_time":"2024-02-14T12:57:35.726639","exception":false,"start_time":"2024-02-14T12:57:35.677247","status":"completed"},"tags":[]}},{"id":"a5a7532a","cell_type":"code","source":"# 欠損値補間\nx_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n\n# 正規化\nfor col in [\"Pclass\", \"Age\"]:\n    value_min = x_train[col].min()\n    value_max = x_train[col].max()\n    x_train[col] = (x_train[col] - value_min) / (value_max - value_min)","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:36.835151Z","iopub.execute_input":"2024-12-19T08:40:36.835535Z","iopub.status.idle":"2024-12-19T08:40:36.844256Z","shell.execute_reply.started":"2024-12-19T08:40:36.835504Z","shell.execute_reply":"2024-12-19T08:40:36.843090Z"},"papermill":{"duration":0.062914,"end_time":"2024-02-14T12:57:35.838979","exception":false,"start_time":"2024-02-14T12:57:35.776065","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":21},{"id":"0e749002","cell_type":"markdown","source":"#### スクリプト6-18: カテゴリ変数の前処理","metadata":{"papermill":{"duration":0.049215,"end_time":"2024-02-14T12:57:35.938243","exception":false,"start_time":"2024-02-14T12:57:35.889028","status":"completed"},"tags":[]}},{"id":"163aac2e","cell_type":"code","source":"# 欠損値補間\nx_train[\"Embarked\"] = x_train[\"Embarked\"].fillna(x_train[\"Embarked\"].mode()[0])\n\n# one-hot-encoding\nohe = OneHotEncoder()\nohe.fit(x_train[[\"Embarked\"]])\ndf_embarked = pd.DataFrame(ohe.transform(x_train[[\"Embarked\"]]).toarray(), \n                           columns=[\"Embarked_{}\".format(col) for col in ohe.categories_[0]])\nx_train = pd.concat([x_train.drop(columns=[\"Embarked\"]), \n                     df_embarked], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:36.845154Z","iopub.execute_input":"2024-12-19T08:40:36.845491Z","iopub.status.idle":"2024-12-19T08:40:36.875276Z","shell.execute_reply.started":"2024-12-19T08:40:36.845464Z","shell.execute_reply":"2024-12-19T08:40:36.873880Z"},"papermill":{"duration":0.06625,"end_time":"2024-02-14T12:57:36.054167","exception":false,"start_time":"2024-02-14T12:57:35.987917","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":22},{"id":"b3cc73e3","cell_type":"markdown","source":"#### スクリプト6-19: 学習データと検証データの分割","metadata":{"papermill":{"duration":0.049318,"end_time":"2024-02-14T12:57:36.154551","exception":false,"start_time":"2024-02-14T12:57:36.105233","status":"completed"},"tags":[]}},{"id":"905933d3","cell_type":"code","source":"x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=123)\nprint(x_tr.shape, x_va.shape, y_tr.shape, y_va.shape)","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:36.879918Z","iopub.execute_input":"2024-12-19T08:40:36.880310Z","iopub.status.idle":"2024-12-19T08:40:36.904965Z","shell.execute_reply.started":"2024-12-19T08:40:36.880274Z","shell.execute_reply":"2024-12-19T08:40:36.903813Z"},"papermill":{"duration":0.070682,"end_time":"2024-02-14T12:57:36.274457","exception":false,"start_time":"2024-02-14T12:57:36.203775","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"(712, 5) (179, 5) (712, 1) (179, 1)\n","output_type":"stream"}],"execution_count":23},{"id":"a7e26a67","cell_type":"markdown","source":"#### スクリプト6-20: モデル定義","metadata":{"papermill":{"duration":0.049009,"end_time":"2024-02-14T12:57:36.372892","exception":false,"start_time":"2024-02-14T12:57:36.323883","status":"completed"},"tags":[]}},{"id":"ab9f12a8","cell_type":"code","source":"def create_model():\n    input_num = Input(shape=(5,))\n    x_num = Dense(10, activation=\"relu\")(input_num)\n    x_num = BatchNormalization()(x_num)\n    x_num = Dropout(0.3)(x_num)\n    x_num = Dense(10, activation=\"relu\")(x_num)\n    x_num = BatchNormalization()(x_num)\n    x_num = Dropout(0.2)(x_num)\n    x_num = Dense(5, activation=\"relu\")(x_num)\n    x_num = BatchNormalization()(x_num)\n    x_num = Dropout(0.1)(x_num)\n    out = Dense(1, activation=\"sigmoid\")(x_num)\n\n    model = Model(inputs=input_num,\n                  outputs=out,\n                 )\n\n    model.compile(\n        optimizer=\"Adam\",\n        loss=\"binary_crossentropy\",\n        metrics=[\"binary_crossentropy\"],\n    )\n    \n    return model\n\nmodel = create_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:36.906858Z","iopub.execute_input":"2024-12-19T08:40:36.907254Z","iopub.status.idle":"2024-12-19T08:40:37.084509Z","shell.execute_reply.started":"2024-12-19T08:40:36.907213Z","shell.execute_reply":"2024-12-19T08:40:37.083627Z"},"papermill":{"duration":0.349435,"end_time":"2024-02-14T12:57:36.771736","exception":false,"start_time":"2024-02-14T12:57:36.422301","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │              \u001b[38;5;34m60\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │              \u001b[38;5;34m40\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │              \u001b[38;5;34m40\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m55\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m20\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m6\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m331\u001b[0m (1.29 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">331</span> (1.29 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m281\u001b[0m (1.10 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">281</span> (1.10 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m50\u001b[0m (200.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> (200.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":24},{"id":"23151e7f","cell_type":"markdown","source":"#### スクリプト6-21: モデル学習","metadata":{"papermill":{"duration":0.053202,"end_time":"2024-02-14T12:57:36.876889","exception":false,"start_time":"2024-02-14T12:57:36.823687","status":"completed"},"tags":[]}},{"id":"dfd534c9-d729-4163-ab98-fa0f14a93fc9","cell_type":"code","source":"seed_everything(seed=123)\nmodel = create_model()\nmodel.fit(x=x_tr,\n          y=y_tr,\n          validation_data=(x_va, y_va),\n          batch_size=8,\n          epochs=10000,\n          callbacks=[\n              # 2024/12/19更新: filepathを「model_keras.h5」から「model_keras.weights.h5」に変更。tensorflowのバージョンアップへの対応。\n              ModelCheckpoint(filepath=\"model_keras.weights.h5\", monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True, save_weights_only=True),\n              EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0, patience=10, verbose=1, restore_best_weights=True),\n              ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.1, patience=5, verbose=1),\n          ],\n          verbose=1,\n         )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T08:40:37.085652Z","iopub.execute_input":"2024-12-19T08:40:37.086043Z","iopub.status.idle":"2024-12-19T08:40:47.578779Z","shell.execute_reply.started":"2024-12-19T08:40:37.086003Z","shell.execute_reply":"2024-12-19T08:40:47.577673Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10000\n\u001b[1m66/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.7255 - loss: 0.7255\nEpoch 1: val_loss improved from inf to 0.64941, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - binary_crossentropy: 0.7288 - loss: 0.7288 - val_binary_crossentropy: 0.6494 - val_loss: 0.6494 - learning_rate: 0.0010\nEpoch 2/10000\n\u001b[1m73/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.7090 - loss: 0.7090\nEpoch 2: val_loss improved from 0.64941 to 0.64184, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.7090 - loss: 0.7090 - val_binary_crossentropy: 0.6418 - val_loss: 0.6418 - learning_rate: 0.0010\nEpoch 3/10000\n\u001b[1m71/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6814 - loss: 0.6814\nEpoch 3: val_loss improved from 0.64184 to 0.63714, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6811 - loss: 0.6811 - val_binary_crossentropy: 0.6371 - val_loss: 0.6371 - learning_rate: 0.0010\nEpoch 4/10000\n\u001b[1m69/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6666 - loss: 0.6666\nEpoch 4: val_loss improved from 0.63714 to 0.63129, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6698 - loss: 0.6698 - val_binary_crossentropy: 0.6313 - val_loss: 0.6313 - learning_rate: 0.0010\nEpoch 5/10000\n\u001b[1m69/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6836 - loss: 0.6836\nEpoch 5: val_loss improved from 0.63129 to 0.62739, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6790 - loss: 0.6790 - val_binary_crossentropy: 0.6274 - val_loss: 0.6274 - learning_rate: 0.0010\nEpoch 6/10000\n\u001b[1m73/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6626 - loss: 0.6626\nEpoch 6: val_loss improved from 0.62739 to 0.62206, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6633 - loss: 0.6633 - val_binary_crossentropy: 0.6221 - val_loss: 0.6221 - learning_rate: 0.0010\nEpoch 7/10000\n\u001b[1m72/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6563 - loss: 0.6563\nEpoch 7: val_loss improved from 0.62206 to 0.61446, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6546 - loss: 0.6546 - val_binary_crossentropy: 0.6145 - val_loss: 0.6145 - learning_rate: 0.0010\nEpoch 8/10000\n\u001b[1m75/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6449 - loss: 0.6449\nEpoch 8: val_loss improved from 0.61446 to 0.60834, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6474 - loss: 0.6474 - val_binary_crossentropy: 0.6083 - val_loss: 0.6083 - learning_rate: 0.0010\nEpoch 9/10000\n\u001b[1m74/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6416 - loss: 0.6416\nEpoch 9: val_loss improved from 0.60834 to 0.60338, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6426 - loss: 0.6426 - val_binary_crossentropy: 0.6034 - val_loss: 0.6034 - learning_rate: 0.0010\nEpoch 10/10000\n\u001b[1m72/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6173 - loss: 0.6173\nEpoch 10: val_loss improved from 0.60338 to 0.59910, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6206 - loss: 0.6206 - val_binary_crossentropy: 0.5991 - val_loss: 0.5991 - learning_rate: 0.0010\nEpoch 11/10000\n\u001b[1m69/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6237 - loss: 0.6237\nEpoch 11: val_loss did not improve from 0.59910\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6260 - loss: 0.6260 - val_binary_crossentropy: 0.6062 - val_loss: 0.6062 - learning_rate: 0.0010\nEpoch 12/10000\n\u001b[1m71/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6299 - loss: 0.6299\nEpoch 12: val_loss did not improve from 0.59910\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6284 - loss: 0.6284 - val_binary_crossentropy: 0.6042 - val_loss: 0.6042 - learning_rate: 0.0010\nEpoch 13/10000\n\u001b[1m69/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6213 - loss: 0.6213\nEpoch 13: val_loss did not improve from 0.59910\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6212 - loss: 0.6212 - val_binary_crossentropy: 0.6029 - val_loss: 0.6029 - learning_rate: 0.0010\nEpoch 14/10000\n\u001b[1m87/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6166 - loss: 0.6166\nEpoch 14: val_loss improved from 0.59910 to 0.58416, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6168 - loss: 0.6168 - val_binary_crossentropy: 0.5842 - val_loss: 0.5842 - learning_rate: 0.0010\nEpoch 15/10000\n\u001b[1m78/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6185 - loss: 0.6185\nEpoch 15: val_loss improved from 0.58416 to 0.58126, saving model to model_keras.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6194 - loss: 0.6194 - val_binary_crossentropy: 0.5813 - val_loss: 0.5813 - learning_rate: 0.0010\nEpoch 16/10000\n\u001b[1m75/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6270 - loss: 0.6270\nEpoch 16: val_loss did not improve from 0.58126\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6267 - loss: 0.6267 - val_binary_crossentropy: 0.5840 - val_loss: 0.5840 - learning_rate: 0.0010\nEpoch 17/10000\n\u001b[1m73/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6104 - loss: 0.6104\nEpoch 17: val_loss did not improve from 0.58126\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6126 - loss: 0.6126 - val_binary_crossentropy: 0.6031 - val_loss: 0.6031 - learning_rate: 0.0010\nEpoch 18/10000\n\u001b[1m67/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6097 - loss: 0.6097\nEpoch 18: val_loss did not improve from 0.58126\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6134 - loss: 0.6134 - val_binary_crossentropy: 0.5924 - val_loss: 0.5924 - learning_rate: 0.0010\nEpoch 19/10000\n\u001b[1m70/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6240 - loss: 0.6240\nEpoch 19: val_loss did not improve from 0.58126\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6271 - loss: 0.6271 - val_binary_crossentropy: 0.5926 - val_loss: 0.5926 - learning_rate: 0.0010\nEpoch 20/10000\n\u001b[1m71/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6393 - loss: 0.6393\nEpoch 20: val_loss did not improve from 0.58126\n\nEpoch 20: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6370 - loss: 0.6370 - val_binary_crossentropy: 0.5921 - val_loss: 0.5921 - learning_rate: 0.0010\nEpoch 21/10000\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.5910 - loss: 0.5910\nEpoch 21: val_loss did not improve from 0.58126\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5911 - loss: 0.5911 - val_binary_crossentropy: 0.5920 - val_loss: 0.5920 - learning_rate: 1.0000e-04\nEpoch 22/10000\n\u001b[1m70/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6090 - loss: 0.6090\nEpoch 22: val_loss did not improve from 0.58126\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6121 - loss: 0.6121 - val_binary_crossentropy: 0.5914 - val_loss: 0.5914 - learning_rate: 1.0000e-04\nEpoch 23/10000\n\u001b[1m71/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6196 - loss: 0.6196\nEpoch 23: val_loss did not improve from 0.58126\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6217 - loss: 0.6217 - val_binary_crossentropy: 0.5911 - val_loss: 0.5911 - learning_rate: 1.0000e-04\nEpoch 24/10000\n\u001b[1m70/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6111 - loss: 0.6111\nEpoch 24: val_loss did not improve from 0.58126\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6125 - loss: 0.6125 - val_binary_crossentropy: 0.5902 - val_loss: 0.5902 - learning_rate: 1.0000e-04\nEpoch 25/10000\n\u001b[1m74/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6132 - loss: 0.6132\nEpoch 25: val_loss did not improve from 0.58126\n\nEpoch 25: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6148 - loss: 0.6148 - val_binary_crossentropy: 0.5901 - val_loss: 0.5901 - learning_rate: 1.0000e-04\nEpoch 25: early stopping\nRestoring model weights from the end of the best epoch: 15.\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x79d576e41b70>"},"metadata":{}}],"execution_count":25},{"id":"88a1c844","cell_type":"markdown","source":"#### スクリプト6-22: モデルの評価","metadata":{"papermill":{"duration":0.082813,"end_time":"2024-02-14T12:57:52.732218","exception":false,"start_time":"2024-02-14T12:57:52.649405","status":"completed"},"tags":[]}},{"id":"d917487d","cell_type":"code","source":"y_va_pred = model.predict(x_va, batch_size=8, verbose=1)\nprint(\"accuracy: {:.4f}\".format(accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))))","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:47.579999Z","iopub.execute_input":"2024-12-19T08:40:47.580375Z","iopub.status.idle":"2024-12-19T08:40:47.888289Z","shell.execute_reply.started":"2024-12-19T08:40:47.580344Z","shell.execute_reply":"2024-12-19T08:40:47.887268Z"},"papermill":{"duration":7.376076,"end_time":"2024-02-14T12:58:00.190917","exception":false,"start_time":"2024-02-14T12:57:52.814841","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\naccuracy: 0.7095\n","output_type":"stream"}],"execution_count":26},{"id":"42b3c37d","cell_type":"markdown","source":"### ニューラルネットワークの適用例：②埋め込み層ありのネットワークモデル\n#### スクリプト6-23: ファイルの読み込みとデータセット作成","metadata":{"papermill":{"duration":0.082158,"end_time":"2024-02-14T12:58:00.354597","exception":false,"start_time":"2024-02-14T12:58:00.272439","status":"completed"},"tags":[]}},{"id":"dc87d1b4","cell_type":"code","source":"# ファイル読み込み\ndf_train = pd.read_csv(\"../input/titanic/train.csv\")\n\n# データセット作成\nx_train = df_train[[\"Pclass\", \"Age\", \"Cabin\"]]\ny_train = df_train[[\"Survived\"]]","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:47.889267Z","iopub.execute_input":"2024-12-19T08:40:47.889547Z","iopub.status.idle":"2024-12-19T08:40:47.901655Z","shell.execute_reply.started":"2024-12-19T08:40:47.889522Z","shell.execute_reply":"2024-12-19T08:40:47.900554Z"},"papermill":{"duration":0.101224,"end_time":"2024-02-14T12:58:00.537528","exception":false,"start_time":"2024-02-14T12:58:00.436304","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":27},{"id":"3382af26","cell_type":"markdown","source":"#### スクリプト6-24: 数値データの前処理","metadata":{"papermill":{"duration":0.081107,"end_time":"2024-02-14T12:58:00.700104","exception":false,"start_time":"2024-02-14T12:58:00.618997","status":"completed"},"tags":[]}},{"id":"d125c5e7","cell_type":"code","source":"# 欠損値補間\nx_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n\n# 正規化\nfor col in [\"Pclass\", \"Age\"]:\n    value_min = x_train[col].min()\n    value_max = x_train[col].max()\n    x_train[col] = (x_train[col] - value_min) / (value_max - value_min)","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:47.902835Z","iopub.execute_input":"2024-12-19T08:40:47.903150Z","iopub.status.idle":"2024-12-19T08:40:47.918274Z","shell.execute_reply.started":"2024-12-19T08:40:47.903123Z","shell.execute_reply":"2024-12-19T08:40:47.916892Z"},"papermill":{"duration":0.097187,"end_time":"2024-02-14T12:58:00.879279","exception":false,"start_time":"2024-02-14T12:58:00.782092","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":28},{"id":"8c8a1857","cell_type":"markdown","source":"#### スクリプト6-25: カテゴリ変数の前処理","metadata":{"papermill":{"duration":0.08279,"end_time":"2024-02-14T12:58:01.047837","exception":false,"start_time":"2024-02-14T12:58:00.965047","status":"completed"},"tags":[]}},{"id":"fc531083","cell_type":"code","source":"# 欠損値補間\nx_train[\"Cabin\"] = x_train[\"Cabin\"].fillna(\"None\")\n\n# label-encoding\nle = LabelEncoder()\nle.fit(x_train[[\"Cabin\"]])\nx_train[\"Cabin\"] = le.transform(x_train[\"Cabin\"])\n\nprint(le.classes_)\nprint(\"count:\", len(le.classes_))","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:47.919652Z","iopub.execute_input":"2024-12-19T08:40:47.919971Z","iopub.status.idle":"2024-12-19T08:40:47.940512Z","shell.execute_reply.started":"2024-12-19T08:40:47.919938Z","shell.execute_reply":"2024-12-19T08:40:47.939417Z"},"papermill":{"duration":0.100191,"end_time":"2024-02-14T12:58:01.232079","exception":false,"start_time":"2024-02-14T12:58:01.131888","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"['A10' 'A14' 'A16' 'A19' 'A20' 'A23' 'A24' 'A26' 'A31' 'A32' 'A34' 'A36'\n 'A5' 'A6' 'A7' 'B101' 'B102' 'B18' 'B19' 'B20' 'B22' 'B28' 'B3' 'B30'\n 'B35' 'B37' 'B38' 'B39' 'B4' 'B41' 'B42' 'B49' 'B5' 'B50' 'B51 B53 B55'\n 'B57 B59 B63 B66' 'B58 B60' 'B69' 'B71' 'B73' 'B77' 'B78' 'B79' 'B80'\n 'B82 B84' 'B86' 'B94' 'B96 B98' 'C101' 'C103' 'C104' 'C106' 'C110' 'C111'\n 'C118' 'C123' 'C124' 'C125' 'C126' 'C128' 'C148' 'C2' 'C22 C26'\n 'C23 C25 C27' 'C30' 'C32' 'C45' 'C46' 'C47' 'C49' 'C50' 'C52' 'C54'\n 'C62 C64' 'C65' 'C68' 'C7' 'C70' 'C78' 'C82' 'C83' 'C85' 'C86' 'C87'\n 'C90' 'C91' 'C92' 'C93' 'C95' 'C99' 'D' 'D10 D12' 'D11' 'D15' 'D17' 'D19'\n 'D20' 'D21' 'D26' 'D28' 'D30' 'D33' 'D35' 'D36' 'D37' 'D45' 'D46' 'D47'\n 'D48' 'D49' 'D50' 'D56' 'D6' 'D7' 'D9' 'E10' 'E101' 'E12' 'E121' 'E17'\n 'E24' 'E25' 'E31' 'E33' 'E34' 'E36' 'E38' 'E40' 'E44' 'E46' 'E49' 'E50'\n 'E58' 'E63' 'E67' 'E68' 'E77' 'E8' 'F E69' 'F G63' 'F G73' 'F2' 'F33'\n 'F38' 'F4' 'G6' 'None' 'T']\ncount: 148\n","output_type":"stream"}],"execution_count":29},{"id":"edf7f092","cell_type":"markdown","source":"#### スクリプト6-26: 学習データと検証データの分離","metadata":{"papermill":{"duration":0.084854,"end_time":"2024-02-14T12:58:01.401933","exception":false,"start_time":"2024-02-14T12:58:01.317079","status":"completed"},"tags":[]}},{"id":"af2acca4","cell_type":"code","source":"x_train_num, x_train_cat = x_train[[\"Pclass\", \"Age\"]], x_train[[\"Cabin\"]]\n\nx_num_tr, x_num_va, x_cat_tr, x_cat_va, y_tr, y_va = \\\n   train_test_split(x_train_num, x_train_cat, y_train, test_size=0.2, stratify=y_train, random_state=123)\nprint(x_num_tr.shape, x_num_va.shape, x_cat_tr.shape, x_cat_va.shape, y_tr.shape, y_va.shape)","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:47.941799Z","iopub.execute_input":"2024-12-19T08:40:47.942163Z","iopub.status.idle":"2024-12-19T08:40:47.971522Z","shell.execute_reply.started":"2024-12-19T08:40:47.942131Z","shell.execute_reply":"2024-12-19T08:40:47.970162Z"},"papermill":{"duration":0.10923,"end_time":"2024-02-14T12:58:01.597279","exception":false,"start_time":"2024-02-14T12:58:01.488049","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"(712, 2) (179, 2) (712, 1) (179, 1) (712, 1) (179, 1)\n","output_type":"stream"}],"execution_count":30},{"id":"34d79888","cell_type":"markdown","source":"#### スクリプト6-27: モデル定義","metadata":{"papermill":{"duration":0.083558,"end_time":"2024-02-14T12:58:01.765647","exception":false,"start_time":"2024-02-14T12:58:01.682089","status":"completed"},"tags":[]}},{"id":"19423a60","cell_type":"code","source":"def create_model_embedding():\n    ################# num\n    input_num = Input(shape=(2,))\n    layer_num = Dense(10, activation=\"relu\")(input_num)\n    layer_num = BatchNormalization()(layer_num)\n    layer_num = Dropout(0.2)(layer_num)\n    layer_num = Dense(10, activation=\"relu\")(layer_num)\n\n    ################# cat\n    input_cat = Input(shape=(1,))\n    layer_cat = input_cat[:, 0]\n    layer_cat = Embedding(input_dim=148, output_dim=74)(layer_cat)\n    layer_cat = Dropout(0.2)(layer_cat)\n    layer_cat = Flatten()(layer_cat)\n\n    ################# concat\n    hidden_layer = Concatenate()([layer_num, layer_cat])\n    hidden_layer = Dense(50, activation=\"relu\")(hidden_layer)\n    hidden_layer = BatchNormalization()(hidden_layer)\n    hidden_layer = Dropout(0.1)(hidden_layer)\n    hidden_layer = Dense(20, activation=\"relu\")(hidden_layer)\n    hidden_layer = BatchNormalization()(hidden_layer)\n    hidden_layer = Dropout(0.1)(hidden_layer)\n    output_layer = Dense(1, activation=\"sigmoid\")(hidden_layer)\n\n    model = Model(inputs=[input_num, input_cat],\n                  outputs=output_layer,\n                 )\n\n    model.compile(\n        optimizer=\"Adam\",\n        loss=\"binary_crossentropy\",\n        metrics=[\"binary_crossentropy\"],\n    )\n    \n    return model\n\nmodel = create_model_embedding()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:47.972315Z","iopub.execute_input":"2024-12-19T08:40:47.972843Z","iopub.status.idle":"2024-12-19T08:40:48.122720Z","shell.execute_reply.started":"2024-12-19T08:40:47.972648Z","shell.execute_reply":"2024-12-19T08:40:48.121801Z"},"papermill":{"duration":0.376199,"end_time":"2024-02-14T12:58:02.225298","exception":false,"start_time":"2024-02-14T12:58:01.849099","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m30\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item (\u001b[38;5;33mGetItem\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m)                 │              \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m40\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)             │         \u001b[38;5;34m10,952\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m110\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n│                           │                        │                │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_10 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │          \u001b[38;5;34m4,250\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │            \u001b[38;5;34m200\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_11 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │          \u001b[38;5;34m1,020\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m80\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m21\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">10,952</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n│                           │                        │                │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,250</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,020</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,703\u001b[0m (65.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,703</span> (65.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,543\u001b[0m (64.62 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,543</span> (64.62 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":31},{"id":"c60cb253","cell_type":"markdown","source":"#### スクリプト6-28: モデルの学習","metadata":{"papermill":{"duration":0.093083,"end_time":"2024-02-14T12:58:02.410109","exception":false,"start_time":"2024-02-14T12:58:02.317026","status":"completed"},"tags":[]}},{"id":"7dd1c45d","cell_type":"code","source":"seed_everything(seed=123)\nmodel = create_model_embedding()\nmodel.fit(x=[x_num_tr, x_cat_tr],\n          y=y_tr,\n          validation_data=([x_num_va, x_cat_va], y_va),\n          batch_size=8,\n          epochs=10000,\n          callbacks=[\n              # 2024/12/19更新: filepathを「model_keras_embedding.h5」から「model_keras_embedding.weights.h5」に変更。tensorflowのバージョンアップへの対応。\n              ModelCheckpoint(filepath=\"model_keras_embedding.weights.h5\", monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True, save_weights_only=True),\n              EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0, patience=10, verbose=1, restore_best_weights=True),\n              ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.1, patience=5, verbose=1),\n          ],\n          verbose=1,\n         )","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:48.123716Z","iopub.execute_input":"2024-12-19T08:40:48.123988Z","iopub.status.idle":"2024-12-19T08:40:56.206113Z","shell.execute_reply.started":"2024-12-19T08:40:48.123965Z","shell.execute_reply":"2024-12-19T08:40:56.205064Z"},"papermill":{"duration":8.217441,"end_time":"2024-02-14T12:58:10.716561","exception":false,"start_time":"2024-02-14T12:58:02.499120","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/10000\n\u001b[1m83/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.7996 - loss: 0.7996\nEpoch 1: val_loss improved from inf to 0.66784, saving model to model_keras_embedding.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - binary_crossentropy: 0.7960 - loss: 0.7960 - val_binary_crossentropy: 0.6678 - val_loss: 0.6678 - learning_rate: 0.0010\nEpoch 2/10000\n\u001b[1m81/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6718 - loss: 0.6718\nEpoch 2: val_loss improved from 0.66784 to 0.64835, saving model to model_keras_embedding.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_crossentropy: 0.6731 - loss: 0.6731 - val_binary_crossentropy: 0.6484 - val_loss: 0.6484 - learning_rate: 0.0010\nEpoch 3/10000\n\u001b[1m86/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.6520 - loss: 0.6520\nEpoch 3: val_loss improved from 0.64835 to 0.62468, saving model to model_keras_embedding.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_crossentropy: 0.6524 - loss: 0.6524 - val_binary_crossentropy: 0.6247 - val_loss: 0.6247 - learning_rate: 0.0010\nEpoch 4/10000\n\u001b[1m75/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.6098 - loss: 0.6098\nEpoch 4: val_loss improved from 0.62468 to 0.59944, saving model to model_keras_embedding.weights.h5\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_crossentropy: 0.6080 - loss: 0.6080 - val_binary_crossentropy: 0.5994 - val_loss: 0.5994 - learning_rate: 0.0010\nEpoch 5/10000\n\u001b[1m78/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5766 - loss: 0.5766\nEpoch 5: val_loss did not improve from 0.59944\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5787 - loss: 0.5787 - val_binary_crossentropy: 0.6123 - val_loss: 0.6123 - learning_rate: 0.0010\nEpoch 6/10000\n\u001b[1m79/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5802 - loss: 0.5802\nEpoch 6: val_loss did not improve from 0.59944\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5811 - loss: 0.5811 - val_binary_crossentropy: 0.6283 - val_loss: 0.6283 - learning_rate: 0.0010\nEpoch 7/10000\n\u001b[1m87/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.5624 - loss: 0.5624\nEpoch 7: val_loss did not improve from 0.59944\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5628 - loss: 0.5628 - val_binary_crossentropy: 0.6332 - val_loss: 0.6332 - learning_rate: 0.0010\nEpoch 8/10000\n\u001b[1m76/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5434 - loss: 0.5434\nEpoch 8: val_loss did not improve from 0.59944\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5481 - loss: 0.5481 - val_binary_crossentropy: 0.6606 - val_loss: 0.6606 - learning_rate: 0.0010\nEpoch 9/10000\n\u001b[1m79/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5658 - loss: 0.5658\nEpoch 9: val_loss did not improve from 0.59944\n\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5664 - loss: 0.5664 - val_binary_crossentropy: 0.6762 - val_loss: 0.6762 - learning_rate: 0.0010\nEpoch 10/10000\n\u001b[1m80/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5270 - loss: 0.5270\nEpoch 10: val_loss did not improve from 0.59944\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5284 - loss: 0.5284 - val_binary_crossentropy: 0.6684 - val_loss: 0.6684 - learning_rate: 1.0000e-04\nEpoch 11/10000\n\u001b[1m83/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_crossentropy: 0.5403 - loss: 0.5403\nEpoch 11: val_loss did not improve from 0.59944\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5405 - loss: 0.5405 - val_binary_crossentropy: 0.6666 - val_loss: 0.6666 - learning_rate: 1.0000e-04\nEpoch 12/10000\n\u001b[1m81/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5670 - loss: 0.5670\nEpoch 12: val_loss did not improve from 0.59944\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5653 - loss: 0.5653 - val_binary_crossentropy: 0.6697 - val_loss: 0.6697 - learning_rate: 1.0000e-04\nEpoch 13/10000\n\u001b[1m80/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5460 - loss: 0.5460\nEpoch 13: val_loss did not improve from 0.59944\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5459 - loss: 0.5459 - val_binary_crossentropy: 0.6715 - val_loss: 0.6715 - learning_rate: 1.0000e-04\nEpoch 14/10000\n\u001b[1m78/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5302 - loss: 0.5302\nEpoch 14: val_loss did not improve from 0.59944\n\nEpoch 14: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_crossentropy: 0.5305 - loss: 0.5305 - val_binary_crossentropy: 0.6765 - val_loss: 0.6765 - learning_rate: 1.0000e-04\nEpoch 14: early stopping\nRestoring model weights from the end of the best epoch: 4.\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x79d56c0b7d60>"},"metadata":{}}],"execution_count":32},{"id":"6971db19","cell_type":"markdown","source":"#### スクリプト6-29: モデル評価","metadata":{"papermill":{"duration":0.099847,"end_time":"2024-02-14T12:58:10.916141","exception":false,"start_time":"2024-02-14T12:58:10.816294","status":"completed"},"tags":[]}},{"id":"fd903232","cell_type":"code","source":"y_va_pred = model.predict([x_num_va, x_cat_va], batch_size=8, verbose=1)\nprint(\"accuracy: {:.4f}\".format(accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))))","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:56.207265Z","iopub.execute_input":"2024-12-19T08:40:56.207564Z","iopub.status.idle":"2024-12-19T08:40:56.609525Z","shell.execute_reply.started":"2024-12-19T08:40:56.207537Z","shell.execute_reply":"2024-12-19T08:40:56.608337Z"},"papermill":{"duration":4.558418,"end_time":"2024-02-14T12:58:15.575010","exception":false,"start_time":"2024-02-14T12:58:11.016592","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\naccuracy: 0.6872\n","output_type":"stream"}],"execution_count":33},{"id":"62ed3404","cell_type":"markdown","source":"# 6.3 アンサンブル\n## 6.3.1 単純平均","metadata":{"papermill":{"duration":0.100622,"end_time":"2024-02-14T12:58:15.776648","exception":false,"start_time":"2024-02-14T12:58:15.676026","status":"completed"},"tags":[]}},{"id":"4b142677","cell_type":"markdown","source":"#### スクリプト6-30: 3モデルの予測値を持つデータフレームを乱数で作成","metadata":{"papermill":{"duration":0.101841,"end_time":"2024-02-14T12:58:15.978802","exception":false,"start_time":"2024-02-14T12:58:15.876961","status":"completed"},"tags":[]}},{"id":"eaee0394","cell_type":"code","source":"np.random.seed(123)\ndf = pd.DataFrame({\n    \"true\": [0]*700 + [1]*300,\n    \"pred1\":np.arange(1000) + np.random.rand(1000)*1200,\n    \"pred2\":np.arange(1000) + np.random.rand(1000)*1000,\n    \"pred3\":np.arange(1000) + np.random.rand(1000)*800,\n})\ndf[\"pred1\"] = np.clip(df[\"pred1\"]/df[\"pred1\"].max(), 0, 1)\ndf[\"pred2\"] = np.clip(df[\"pred2\"]/df[\"pred2\"].max(), 0, 1)\ndf[\"pred3\"] = np.clip(df[\"pred3\"]/df[\"pred3\"].max(), 0, 1)\n\ndf_train, df_test = train_test_split(df, test_size=0.8, stratify=df[\"true\"], random_state=123)\ndf_train = df_train.reset_index(drop=True)\ndf_test = df_test.reset_index(drop=True)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:56.610552Z","iopub.execute_input":"2024-12-19T08:40:56.610839Z","iopub.status.idle":"2024-12-19T08:40:56.637350Z","shell.execute_reply.started":"2024-12-19T08:40:56.610815Z","shell.execute_reply":"2024-12-19T08:40:56.636041Z"},"papermill":{"duration":0.139793,"end_time":"2024-02-14T12:58:16.222630","exception":false,"start_time":"2024-02-14T12:58:16.082837","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"   true     pred1     pred2     pred3\n0     1  0.683821  0.874443  0.859939\n1     0  0.540691  0.113419  0.197144\n2     0  0.310541  0.334798  0.599304\n3     0  0.043486  0.170622  0.378528\n4     0  0.550847  0.354703  0.598860","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>true</th>\n      <th>pred1</th>\n      <th>pred2</th>\n      <th>pred3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.683821</td>\n      <td>0.874443</td>\n      <td>0.859939</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.540691</td>\n      <td>0.113419</td>\n      <td>0.197144</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.310541</td>\n      <td>0.334798</td>\n      <td>0.599304</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.043486</td>\n      <td>0.170622</td>\n      <td>0.378528</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.550847</td>\n      <td>0.354703</td>\n      <td>0.598860</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":34},{"id":"798633bc","cell_type":"markdown","source":"#### スクリプト6-31: 単純平均によるアンサンブル","metadata":{"papermill":{"duration":0.100758,"end_time":"2024-02-14T12:58:16.424427","exception":false,"start_time":"2024-02-14T12:58:16.323669","status":"completed"},"tags":[]}},{"id":"33cf2f43","cell_type":"code","source":"df_train[\"pred_ensemble1\"] = (df_train[\"pred1\"] + df_train[\"pred2\"] + df_train[\"pred3\"]) / 3\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:56.638396Z","iopub.execute_input":"2024-12-19T08:40:56.638789Z","iopub.status.idle":"2024-12-19T08:40:56.653839Z","shell.execute_reply.started":"2024-12-19T08:40:56.638758Z","shell.execute_reply":"2024-12-19T08:40:56.652276Z"},"papermill":{"duration":0.121099,"end_time":"2024-02-14T12:58:16.646555","exception":false,"start_time":"2024-02-14T12:58:16.525456","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"   true     pred1     pred2     pred3  pred_ensemble1\n0     1  0.683821  0.874443  0.859939        0.806068\n1     0  0.540691  0.113419  0.197144        0.283752\n2     0  0.310541  0.334798  0.599304        0.414881\n3     0  0.043486  0.170622  0.378528        0.197545\n4     0  0.550847  0.354703  0.598860        0.501470","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>true</th>\n      <th>pred1</th>\n      <th>pred2</th>\n      <th>pred3</th>\n      <th>pred_ensemble1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.683821</td>\n      <td>0.874443</td>\n      <td>0.859939</td>\n      <td>0.806068</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.540691</td>\n      <td>0.113419</td>\n      <td>0.197144</td>\n      <td>0.283752</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.310541</td>\n      <td>0.334798</td>\n      <td>0.599304</td>\n      <td>0.414881</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.043486</td>\n      <td>0.170622</td>\n      <td>0.378528</td>\n      <td>0.197545</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.550847</td>\n      <td>0.354703</td>\n      <td>0.598860</td>\n      <td>0.501470</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"id":"9fd1f62f","cell_type":"markdown","source":"#### スクリプト6-32: アンサンブル用の精度評価関数と、精度評価","metadata":{"papermill":{"duration":0.100182,"end_time":"2024-02-14T12:58:16.849762","exception":false,"start_time":"2024-02-14T12:58:16.749580","status":"completed"},"tags":[]}},{"id":"1a3f2e9a","cell_type":"code","source":"def evaluate_ensemble(input_df, col_pred):\n    print(\"[auc] model1:{:.4f}, model2:{:.4f}, model3:{:.4f} -> ensemble:{:.4f}\".format(\n        roc_auc_score(input_df[\"true\"], input_df[\"pred1\"]),\n        roc_auc_score(input_df[\"true\"], input_df[\"pred2\"]),\n        roc_auc_score(input_df[\"true\"], input_df[\"pred3\"]),\n        roc_auc_score(input_df[\"true\"], input_df[col_pred]),\n    ))\n\nevaluate_ensemble(df_train, col_pred=\"pred_ensemble1\")","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:56.654939Z","iopub.execute_input":"2024-12-19T08:40:56.655266Z","iopub.status.idle":"2024-12-19T08:40:56.681383Z","shell.execute_reply.started":"2024-12-19T08:40:56.655238Z","shell.execute_reply":"2024-12-19T08:40:56.680101Z"},"papermill":{"duration":0.129429,"end_time":"2024-02-14T12:58:17.083770","exception":false,"start_time":"2024-02-14T12:58:16.954341","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9585\n","output_type":"stream"}],"execution_count":36},{"id":"9641b38a","cell_type":"markdown","source":"#### スクリプト6-33: 推論時のアンサンブル処理と、精度評価","metadata":{"papermill":{"duration":0.104086,"end_time":"2024-02-14T12:58:17.290956","exception":false,"start_time":"2024-02-14T12:58:17.186870","status":"completed"},"tags":[]}},{"id":"96951f2f","cell_type":"code","source":"df_test[\"pred_ensemble1\"] = (df_test[\"pred1\"] + df_test[\"pred2\"] + df_test[\"pred3\"]) / 3\nevaluate_ensemble(df_test, col_pred=\"pred_ensemble1\")","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:56.682376Z","iopub.execute_input":"2024-12-19T08:40:56.682687Z","iopub.status.idle":"2024-12-19T08:40:56.698732Z","shell.execute_reply.started":"2024-12-19T08:40:56.682641Z","shell.execute_reply":"2024-12-19T08:40:56.697444Z"},"papermill":{"duration":0.122226,"end_time":"2024-02-14T12:58:17.517349","exception":false,"start_time":"2024-02-14T12:58:17.395123","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9396\n","output_type":"stream"}],"execution_count":37},{"id":"a14646cf","cell_type":"markdown","source":"## 6.3.2 重み付き平均","metadata":{"papermill":{"duration":0.100762,"end_time":"2024-02-14T12:58:17.720596","exception":false,"start_time":"2024-02-14T12:58:17.619834","status":"completed"},"tags":[]}},{"id":"45db00a7","cell_type":"markdown","source":"#### スクリプト6-34: 重み付き平均によるアンサンブル","metadata":{"papermill":{"duration":0.102666,"end_time":"2024-02-14T12:58:17.923967","exception":false,"start_time":"2024-02-14T12:58:17.821301","status":"completed"},"tags":[]}},{"id":"8c195ff4","cell_type":"code","source":"weight = [0.3, 0.3, 0.4]\nweight = weight / np.sum(weight)\nprint(weight)\n\ndf_train[\"pred_ensemble2\"] = df_train[\"pred1\"] * weight[0] + \\\n                             df_train[\"pred2\"] * weight[1] + \\\n                             df_train[\"pred3\"] * weight[2]\ndf_train[[\"true\",\"pred1\",\"pred2\",\"pred3\",\"pred_ensemble2\"]].head()","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:56.699761Z","iopub.execute_input":"2024-12-19T08:40:56.700126Z","iopub.status.idle":"2024-12-19T08:40:56.718238Z","shell.execute_reply.started":"2024-12-19T08:40:56.700085Z","shell.execute_reply":"2024-12-19T08:40:56.716869Z"},"papermill":{"duration":0.124813,"end_time":"2024-02-14T12:58:18.150973","exception":false,"start_time":"2024-02-14T12:58:18.026160","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"[0.3 0.3 0.4]\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"   true     pred1     pred2     pred3  pred_ensemble2\n0     1  0.683821  0.874443  0.859939        0.811455\n1     0  0.540691  0.113419  0.197144        0.275091\n2     0  0.310541  0.334798  0.599304        0.433324\n3     0  0.043486  0.170622  0.378528        0.215643\n4     0  0.550847  0.354703  0.598860        0.511209","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>true</th>\n      <th>pred1</th>\n      <th>pred2</th>\n      <th>pred3</th>\n      <th>pred_ensemble2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.683821</td>\n      <td>0.874443</td>\n      <td>0.859939</td>\n      <td>0.811455</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.540691</td>\n      <td>0.113419</td>\n      <td>0.197144</td>\n      <td>0.275091</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.310541</td>\n      <td>0.334798</td>\n      <td>0.599304</td>\n      <td>0.433324</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.043486</td>\n      <td>0.170622</td>\n      <td>0.378528</td>\n      <td>0.215643</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.550847</td>\n      <td>0.354703</td>\n      <td>0.598860</td>\n      <td>0.511209</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"id":"acfba442","cell_type":"markdown","source":"#### スクリプト6-35: アンサンブルの精度評価","metadata":{"papermill":{"duration":0.104315,"end_time":"2024-02-14T12:58:18.357366","exception":false,"start_time":"2024-02-14T12:58:18.253051","status":"completed"},"tags":[]}},{"id":"1aa4d001","cell_type":"code","source":"evaluate_ensemble(df_train, col_pred=\"pred_ensemble2\")","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:56.719513Z","iopub.execute_input":"2024-12-19T08:40:56.720067Z","iopub.status.idle":"2024-12-19T08:40:56.743405Z","shell.execute_reply.started":"2024-12-19T08:40:56.720020Z","shell.execute_reply":"2024-12-19T08:40:56.742264Z"},"papermill":{"duration":0.186616,"end_time":"2024-02-14T12:58:18.645885","exception":false,"start_time":"2024-02-14T12:58:18.459269","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9614\n","output_type":"stream"}],"execution_count":39},{"id":"8115cb6a","cell_type":"markdown","source":"#### スクリプト6-36: 推論時のアンサンブル処理と、精度評価","metadata":{"papermill":{"duration":0.101403,"end_time":"2024-02-14T12:58:18.850520","exception":false,"start_time":"2024-02-14T12:58:18.749117","status":"completed"},"tags":[]}},{"id":"7e541381","cell_type":"code","source":"df_test[\"pred_ensemble2\"] = df_test[\"pred1\"] * weight[0] + \\\n                            df_test[\"pred2\"] * weight[1] + \\\n                            df_test[\"pred3\"] * weight[2]\nevaluate_ensemble(df_test, col_pred=\"pred_ensemble2\")","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:56.744674Z","iopub.execute_input":"2024-12-19T08:40:56.745063Z","iopub.status.idle":"2024-12-19T08:40:56.766204Z","shell.execute_reply.started":"2024-12-19T08:40:56.745026Z","shell.execute_reply":"2024-12-19T08:40:56.765075Z"},"papermill":{"duration":0.126801,"end_time":"2024-02-14T12:58:19.079175","exception":false,"start_time":"2024-02-14T12:58:18.952374","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9420\n","output_type":"stream"}],"execution_count":40},{"id":"30ad3e16","cell_type":"markdown","source":"## 6.3.3 スタッキング","metadata":{"papermill":{"duration":0.103004,"end_time":"2024-02-14T12:58:19.285302","exception":false,"start_time":"2024-02-14T12:58:19.182298","status":"completed"},"tags":[]}},{"id":"d62fd509","cell_type":"markdown","source":"#### スクリプト6-37: スタッキングによるアンサンブル","metadata":{"papermill":{"duration":0.102093,"end_time":"2024-02-14T12:58:19.491665","exception":false,"start_time":"2024-02-14T12:58:19.389572","status":"completed"},"tags":[]}},{"id":"9099b4b6","cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nx, y = df_train[[\"pred1\", \"pred2\", \"pred3\"]], df_train[[\"true\"]]\noof = np.zeros(len(x))\nmodels = []\n\ncv = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(x, y))\nfor nfold in np.arange(5):\n    # 学習データと検証データの分離\n    idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n    x_tr, y_tr = x.loc[idx_tr, :], y.loc[idx_tr, :]\n    x_va, y_va = x.loc[idx_va, :], y.loc[idx_va, :]\n    \n    # モデル学習\n    model = Lasso(alpha=0.01)\n    model.fit(x_tr, y_tr)\n    models.append(model)\n    \n    # 検証データの予測値算出\n    y_va_pred = model.predict(x_va)\n    oof[idx_va] = y_va_pred\n    \ndf_train[\"pred_ensemble3\"] = oof\ndf_train[\"pred_ensemble3\"] = df_train[\"pred_ensemble3\"].clip(lower=0, upper=1)\ndf_train[[\"true\",\"pred1\",\"pred2\",\"pred3\",\"pred_ensemble3\"]].head()","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:56.767437Z","iopub.execute_input":"2024-12-19T08:40:56.767843Z","iopub.status.idle":"2024-12-19T08:40:56.819345Z","shell.execute_reply.started":"2024-12-19T08:40:56.767807Z","shell.execute_reply":"2024-12-19T08:40:56.818358Z"},"papermill":{"duration":0.172318,"end_time":"2024-02-14T12:58:19.766094","exception":false,"start_time":"2024-02-14T12:58:19.593776","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"   true     pred1     pred2     pred3  pred_ensemble3\n0     1  0.683821  0.874443  0.859939        0.745020\n1     0  0.540691  0.113419  0.197144        0.000000\n2     0  0.310541  0.334798  0.599304        0.206734\n3     0  0.043486  0.170622  0.378528        0.000000\n4     0  0.550847  0.354703  0.598860        0.303498","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>true</th>\n      <th>pred1</th>\n      <th>pred2</th>\n      <th>pred3</th>\n      <th>pred_ensemble3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.683821</td>\n      <td>0.874443</td>\n      <td>0.859939</td>\n      <td>0.745020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.540691</td>\n      <td>0.113419</td>\n      <td>0.197144</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.310541</td>\n      <td>0.334798</td>\n      <td>0.599304</td>\n      <td>0.206734</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.043486</td>\n      <td>0.170622</td>\n      <td>0.378528</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.550847</td>\n      <td>0.354703</td>\n      <td>0.598860</td>\n      <td>0.303498</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":41},{"id":"5161c111","cell_type":"markdown","source":"#### スクリプト6-38: アンサンブルの精度評価","metadata":{"papermill":{"duration":0.103026,"end_time":"2024-02-14T12:58:19.971151","exception":false,"start_time":"2024-02-14T12:58:19.868125","status":"completed"},"tags":[]}},{"id":"3b9fbd7d","cell_type":"code","source":"evaluate_ensemble(df_train, col_pred=\"pred_ensemble3\")","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:56.820402Z","iopub.execute_input":"2024-12-19T08:40:56.820682Z","iopub.status.idle":"2024-12-19T08:40:56.832108Z","shell.execute_reply.started":"2024-12-19T08:40:56.820650Z","shell.execute_reply":"2024-12-19T08:40:56.831130Z"},"papermill":{"duration":0.120483,"end_time":"2024-02-14T12:58:20.198478","exception":false,"start_time":"2024-02-14T12:58:20.077995","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9577\n","output_type":"stream"}],"execution_count":42},{"id":"bcec4c31","cell_type":"markdown","source":"#### スクリプト6-39: 推論時のアンサンブル処理と、精度評価","metadata":{"papermill":{"duration":0.102582,"end_time":"2024-02-14T12:58:20.403935","exception":false,"start_time":"2024-02-14T12:58:20.301353","status":"completed"},"tags":[]}},{"id":"baa4ada2","cell_type":"code","source":"df_test[\"pred_ensemble3\"] = 0\nfor model in models:\n    df_test[\"pred_ensemble3\"] += model.predict(df_test[[\"pred1\", \"pred2\", \"pred3\"]]) / len(models)\ndf_test[\"pred_ensemble3\"] = df_test[\"pred_ensemble3\"].clip(lower=0, upper=1)\nevaluate_ensemble(df_test, col_pred=\"pred_ensemble3\")","metadata":{"execution":{"iopub.status.busy":"2024-12-19T08:40:56.833431Z","iopub.execute_input":"2024-12-19T08:40:56.833808Z","iopub.status.idle":"2024-12-19T08:40:56.870202Z","shell.execute_reply.started":"2024-12-19T08:40:56.833768Z","shell.execute_reply":"2024-12-19T08:40:56.869139Z"},"papermill":{"duration":0.140976,"end_time":"2024-02-14T12:58:20.647119","exception":false,"start_time":"2024-02-14T12:58:20.506143","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9437\n","output_type":"stream"}],"execution_count":43},{"id":"262ed40f","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.103363,"end_time":"2024-02-14T12:58:20.853577","exception":false,"start_time":"2024-02-14T12:58:20.750214","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"a5acf1ec","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.109538,"end_time":"2024-02-14T12:58:21.066076","exception":false,"start_time":"2024-02-14T12:58:20.956538","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}